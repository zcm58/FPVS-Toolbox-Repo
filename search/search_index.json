{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"FPVS Toolbox Documentation","text":"<p>The Fast Periodic Visual Stimulation (FPVS) Toolbox allows you to easily process EEG data from FPVS experiments and run statistical analyses on the resulting metrics. As of now, FPVS Toolbox only supports the BioSemi data format (.BDF) and FPVS experiments ran with PsychoPy. </p> <p>This documentation page is a work in progress and is not yet complete.</p> <p>Current app version: v1.5.0</p>"},{"location":"#quick-start","title":"Quick start","text":"<ol> <li>Install FPVS Toolbox    Download the latest installer from the GitHub Releases page and run it    on Windows. You may have to bypass Windows Defender if prompted. When you run FPVS Toolbox for the first time, you    will be asked to select a \"Project Root\". This is where all the different results from various projects you create    within FPVS Toolbox will live. I recommend that you avoid using cloud based folders like OneDrive - it sometimes    causes issues with Statistical Analysis. </li> </ol> <ol> <li>Create or open a project </li> </ol> <p>From the main window, choose \"Create New Project\". You will be prompted to title your project, select the number of experimental groups, and to name each group. Next, you will select the input folder for each group (wherever you have stored your .BDF files).</p> <p>You will need to input titles for each FPVS Condition in your experiment in the Main App GUI, as well as the     PsychoPy trigger code associated with that condition. </p> <ol> <li>Process EEG data </li> <li>Select an EEG file or batch folder.  </li> <li>Configure preprocessing (reference, downsampling, filters, artifact      handling) in the Settings panel.  </li> <li> <p>Click Start Processing to run the pipeline and generate metrics      and Excel outputs.</p> </li> <li> <p>Run statistical analysis</p> </li> <li> <p>Open Statistical Analysis in the sidebar to run single-group or    between-group analyses on the processed data.</p> </li> </ol>"},{"location":"#core-documentation","title":"Core documentation","text":"<ul> <li> <p>Processing Pipeline   Detailed description of how recordings are loaded, preprocessed, epoched,   and converted to frequency-domain metrics.</p> </li> <li> <p>Statistical Analysis   Overview of single-group and between-group analyses, models used, and   how to interpret the outputs.</p> </li> <li> <p>Relevant Publications   A brief overview of relevant publications on FPVS and the preprocessing pipeline used inside the FPVS Toolbox. </p> </li> <li> <p>Tutorials &amp; Walkthroughs   Step-by-step examples on how to use the FPVS Toolbox.</p> </li> </ul>"},{"location":"#project-links","title":"Project links","text":"<ul> <li>GitHub repository: <code>https://github.com/zcm58/FPVS-Toolbox-Repo&gt;</code></li> </ul>"},{"location":"processing-pipeline/","title":"Processing Pipeline","text":"<p>This page describes how the FPVS Toolbox processes EEG data from raw recordings to frequency-domain metrics and ROI-level summaries.</p> <p>The pipeline is designed to mirror a standard processing pipeline using MATLAB and EEGLab. Please see the relevant  publications for more information on this methodology. </p>"},{"location":"processing-pipeline/#overview","title":"Overview","text":"<p>At a high level, the FPVS Toolbox:</p> <ol> <li>Loads a raw FPVS recording (BioSemi <code>.bdf</code>) using    a disk-backed memory map.</li> <li>Applies a standardized preprocessing pipeline (referencing, filtering,    artifact handling, final average reference).</li> <li>Extracts events for user-defined conditions and creates epochs around    each stimulus type.</li> <li>Computes frequency-domain spectra and FPVS metrics (e.g., SNR, baseline-    corrected amplitudes) at the tag frequency and harmonics.</li> <li>Aggregates results within user-defined ROIs and exports per-condition,    per-ROI summaries to Excel for downstream statistics.</li> </ol> <p>Each step is logged to the FPVS Toolbox log window and log file so users can reconstruct the full processing history for a given project.</p>"},{"location":"processing-pipeline/#1-loading-recordings","title":"1. Loading recordings","text":"<p>When you select a single file or a batch folder, the loader:</p> <ul> <li> <p>Resolves the stimulus channel   The toolbox chooses the stim channel specified in project settings   (default: <code>Status</code>) and assigns it the MNE <code>stim</code> type.</p> </li> <li> <p>Resolves the initial reference pair   A pair of EXG channels (default: <code>EXG1</code> / <code>EXG2</code>) is treated as the   initial EEG reference. These channels are kept as EEG during loading.</p> </li> <li> <p>Reads the recording with MNE  </p> </li> <li>BioSemi recordings are loaded with <code>mne.io.read_raw_bdf</code>.</li> <li> <p>EEGLAB files are loaded via MNE\u2019s EEGLAB reader.   In both cases, a disk-backed memory map is used when possible to limit   RAM usage on large datasets.</p> </li> <li> <p>Applies a standard montage   After loading, a standard 10\u201320 montage is applied to EEG channels so   channel locations are available for interpolation and ROI aggregation.   Any non-EEG auxiliary channels are typed appropriately (e.g., EXG \u2192 <code>misc</code>   after referencing, stim \u2192 <code>stim</code>).</p> </li> </ul>"},{"location":"processing-pipeline/#2-preprocessing-pipeline","title":"2. Preprocessing pipeline","text":"<p>The preprocessing pipeline is applied in a fixed order to keep behavior consistent across projects.</p>"},{"location":"processing-pipeline/#21-initial-referencing","title":"2.1 Initial referencing","text":"<ul> <li>The user-selected reference pair (by default, <code>EXG1</code> / <code>EXG2</code>) is   coerced to EEG type if needed.</li> <li>MNE\u2019s <code>set_eeg_reference</code> is used to subtract the average of these two   reference channels from all EEG channels.</li> <li>Audit flags are recorded so that the log reflects whether referencing   succeeded and which channels were used.</li> </ul>"},{"location":"processing-pipeline/#22-drop-reference-channels","title":"2.2 Drop reference channels","text":"<p>After re-referencing:</p> <ul> <li>The two reference channels are removed from the dataset, so they do not   contribute to later average-reference and ROI computations.</li> </ul>"},{"location":"processing-pipeline/#23-optional-channel-limit","title":"2.3 Optional channel limit","text":"<p>If a maximum EEG channel count is configured in project settings:</p> <ul> <li>Channels beyond that index are dropped to keep a consistent subset of   sensors across recordings.</li> <li>The stim channel is preserved even if it would otherwise be outside   the limit.</li> </ul>"},{"location":"processing-pipeline/#24-downsampling-optional","title":"2.4 Downsampling (optional)","text":"<p>If downsampling is enabled and the original sampling rate is higher than the chosen target:</p> <ul> <li>Data are resampled using MNE\u2019s resampling routines with a Hann window.</li> <li>Downsampling occurs before filtering to reduce computation and   keep filter design consistent.</li> </ul>"},{"location":"processing-pipeline/#25-fir-filtering","title":"2.5 FIR filtering","text":"<p>A zero-phase FIR filter is applied to the (possibly downsampled) data:</p> <ul> <li>Legacy parameters are mirrored:</li> <li>The GUI \u201chigh-pass\u201d setting maps to the filter\u2019s <code>l_freq</code>.</li> <li>The GUI \u201clow-pass\u201d setting maps to <code>h_freq</code>.</li> <li>Fixed transition bandwidths and filter lengths are chosen to match     the original toolbox behavior as closely as possible.</li> <li>Filtering is applied in a way that avoids phase distortion   (forward-and-backward filtering).</li> </ul>"},{"location":"processing-pipeline/#26-kurtosis-based-artifact-handling","title":"2.6 Kurtosis-based artifact handling","text":"<p>To identify noisy channels:</p> <ul> <li>EEG channels (excluding previously marked bads and non-EEG/stim   channels) are scored using a kurtosis-based metric.</li> <li>Channels whose kurtosis exceeds a configurable Z-score threshold are:</li> <li>Marked as bad (added to <code>raw.info[\"bads\"]</code>).</li> <li>Interpolated when a montage is available, using neighboring     electrodes to estimate the signal.</li> </ul>"},{"location":"processing-pipeline/#27-final-average-reference","title":"2.7 Final average reference","text":"<p>After bad-channel handling:</p> <ul> <li>Remaining good EEG channels are re-referenced to the average.</li> <li>Any pending projections are applied.</li> <li>Preprocessing completes with logging of:</li> <li>Final channel count (total and bads).</li> <li>Final sampling rate.</li> <li>Filter settings, artifact thresholds, and reference choices.</li> </ul>"},{"location":"processing-pipeline/#3-event-extraction-and-epoching","title":"3. Event extraction and epoching","text":"<p>The event and epoching step mirrors the legacy flow but is configured via the PySide6 GUI.</p>"},{"location":"processing-pipeline/#31-event-detection","title":"3.1 Event detection","text":"<p>Events are derived in one of two ways:</p> <ol> <li> <p>From annotations    If the recording contains MNE annotations that correspond to your    condition IDs, they are mapped directly using the IDs and labels you    configure in the Event Map. </p> </li> <li> <p>From the stim channel    If annotations are not available, events are detected from the stim    channel (e.g., <code>Status</code>) using <code>mne.find_events</code>.  </p> </li> <li>The IDs you configure in the Event Map (e.g., '21' for      \u201cCondition ABC\u201d) are matched to codes on the stim channel.</li> <li>Empty event sets (no events found for a given ID) are logged as      warnings.</li> </ol>"},{"location":"processing-pipeline/#32-epoch-creation","title":"3.2 Epoch creation","text":"<p>For each label/ID pair defined in the Event Map:</p> <ul> <li> <p>MNE <code>Epochs</code> objects are created with user-specified start and end   times relative to each event (e.g., from \u22120.5 s to +5.0 s). In FPVS Experiments, <code>Epochs</code> refer to one  experimental condition. Each condition must be analyzed separately. </p> </li> <li> <p>Successful epoch sets are stored per condition label and used for   downstream spectral analysis and metric computation.</p> </li> </ul>"},{"location":"processing-pipeline/#4-frequency-domain-analysis","title":"4. Frequency-domain analysis","text":"<p>Once epochs are defined, the FPVS Toolbox computes frequency-domain responses for each condition.</p> <p>In brief:</p> <ol> <li>FFT per epoch and channel </li> <li> <p>A Fourier transform is applied to each epoch to obtain amplitude      spectra at frequencies of interest.</p> </li> <li> <p>Tag frequency and harmonics </p> </li> <li> <p>The fundamental FPVS stimulation frequency and a configurable number      of harmonics are selected for metric computation.</p> </li> <li> <p>Baseline regions </p> </li> <li>Surrounding \u201cnoise\u201d frequency bins (excluding the signal bin and      its immediate neighbors) define a baseline used for SNR and      baseline-corrected measures.</li> </ol>"},{"location":"processing-pipeline/#5-fpvs-metrics-snr-baseline-corrected-amplitude","title":"5. FPVS metrics (SNR, baseline-corrected amplitude)","text":"<p>For each channel, condition, and harmonic, the toolbox computes the following metrics: </p> <ul> <li>SNR (Signal-to-Noise Ratio) </li> </ul> <p>In frequency-domain analyses of fast periodic visual stimulation (FPVS) with electroencephalography (EEG), signal-to-noise ratio (SNR) is a core metric for quantifying neural responses at stimulation frequencies. Within oddball paradigms where deviant stimuli are periodically included among a stream of base images, SNR provides a robust, objective estimate of response strength at the oddball frequency and its harmonics. The standard method for calculating SNR involves dividing the amplitude at the frequency of interest by the mean amplitude of surrounding frequency bins, assumed to reflect background noise (Rossion et al., 2015; Zimmermann et al., 2019). A methodological consensus has emerged around the use of a 20-bin local noise window\u201410 bins on either side of the target frequency\u2014with specific exclusions to ensure a clean estimate. First, the immediately adjacent frequency bins are systematically excluded to mitigate contamination from spectral leakage of the target response (Stothart et al., 2017; Georges et al., 2020). Second, many studies further discard the two most extreme amplitude values among the noise bins (i.e., the highest and lowest), which can otherwise inflate or deflate the average due to unrelated spectral artifacts or narrowband EEG noise (Dzhelyova &amp; Rossion, 2014a; Poncet et al., 2019). For example, Georges et al. (2020) and Zimmermann et al. (2019) both implemented this 20-bin \u00b110 approach, excluding the neighboring bins as well as the extreme values to derive a robust noise floor. This practice, introduced in foundational studies (e.g., Liu-Shuang et al., 2014), ensures the SNR reflects genuine periodic neural responses rather than local noise fluctuations or harmonics from unrelated sources. The resulting SNR values are used not only for individual participant-level inference but also for generating z-scores and evaluating signal strength across scalp topographies. Because the frequency bins used for noise estimation are drawn from the same power spectrum and close in frequency to the signal bin, this method yields a locally normalized, frequency-specific measure that is highly sensitive to subtle categorical effects in the EEG signal (Rossion et al., 2015; Poncet et al., 2019).</p> <p>References</p> <ul> <li>Dzhelyova, M., &amp; Rossion, B. (2014a). The effect of parametric stimulus variation on individual face discrimination indexed by fast periodic visual stimulation. Journal of Vision, 14(12), 1\u201318. https://doi.org/10.1167/14.12.22</li> <li>Georges, C., Retter, T. L., &amp; Rossion, B. (2020). Face-selective responses in the human brain: A periodic stimulation approach. NeuroImage, 214, 116703. https://doi.org/10.1016/j.neuroimage.2020.116703</li> <li>Liu-Shuang, J., Norcia, A. M., &amp; Rossion, B. (2014). An objective index of individual face discrimination in the right occipito-temporal cortex by means of fast periodic oddball stimulation. Neuropsychologia, 52, 57\u201372. https://doi.org/10.1016/j.neuropsychologia.2013.10.022</li> <li>Poncet, F., Rossion, B., &amp; Jacques, C. (2019). Evidence for the existence of a face-selective neural response in the human brain with fast periodic visual stimulation. NeuroImage, 189, 150\u2013162. https://doi.org/10.1016/j.neuroimage.2019.01.021</li> <li>Rossion, B., Torfs, K., Jacques, C., &amp; Liu-Shuang, J. (2015). Fast periodic presentation of natural images reveals a robust face-selective electrophysiological response in the human brain. Journal of Vision, 15(1), 1\u201318. https://doi.org/10.1167/15.1.15</li> <li>Stothart, G., Quadflieg, S., &amp; Kazanina, N. (2017). Semantic processing in the human brain: Electrophysiological evidence from fast periodic visual stimulation. Neuropsychologia, 100, 57\u201363. https://doi.org/10.1016/j.neuropsychologia.2017.03.006</li> <li>Zimmermann, J. F., Groh-Bordin, C., &amp; Roesler, F. (2019). Familiarity and identity-specificity of face representations in fast periodic visual stimulation. NeuroImage, 193, 162\u2013171. https://doi.org/10.1016/j.neuroimage.2019.03.026</li> </ul> <p>Baseline-corrected amplitude (BCA) </p> <p>Amplitude at the target bin minus the baseline estimate.</p> <p>Z-Scores (placeholder)</p> <p>Need to include some information regarding Z-Scores here. </p> <p>These metrics are then aggregated:</p> <ul> <li>Across epochs for each subject and condition.</li> <li>Across channels belonging to each user-defined ROI.</li> </ul> <p>The resulting ROI-level SNR and BCA values form the basis of the statistical analyses run in the Stats tool.</p>"},{"location":"processing-pipeline/#6-roi-aggregation-and-exports","title":"6. ROI aggregation and exports","text":"<p>The final steps of the processing pipeline are:</p> <ol> <li>ROI aggregation </li> <li>Channels are grouped into ROIs defined in project settings      (e.g., left occipital, right occipital, frontal, parietal).</li> <li> <p>Metrics are averaged within each ROI for each subject, condition,      and harmonic.</p> </li> <li> <p>Excel exports </p> </li> <li>Per-subject, per-condition, and per-ROI summaries are written to      Excel files in the project\u2019s Results folder.</li> <li> <p>These Excel outputs are used directly by the Statistical Analysis      module for single-group and between-group models.</p> </li> <li> <p>Logging and audit trail </p> </li> <li>Each successfully processed file contributes to a batch summary      (number of files, rejected channels, etc.).</li> <li>The logs provide a full audit trail of the processing settings used      for a given project and batch.</li> </ol>"},{"location":"processing-pipeline/#notes-and-best-practices","title":"Notes and best practices","text":"<ul> <li>Keep preprocessing settings consistent within a project so that metrics   are comparable across subjects and sessions.</li> <li>Verify event IDs and epoch time windows before running large batch   jobs; incorrect event mappings can silently produce empty conditions.</li> <li>When publishing results, include key pipeline settings (reference,   filter bands, artifact thresholds, and epoch windows) in the Methods   section, ideally referencing this documentation for additional detail.</li> </ul>"},{"location":"relevant-publications/","title":"Relevant Publications","text":"<p>This page lists key articles and books that informed the design of the FPVS Toolbox, including choices in paradigm design, preprocessing, and statistical analysis. It is not exhaustive, but it should give users a solid starting point to understand the methods behind the software.</p>"},{"location":"relevant-publications/#fpvs-ssvep-and-frequency-tagging-paradigms","title":"FPVS, SSVEP, and Frequency-Tagging Paradigms","text":"<ul> <li> <p>Vandenheever et. al, 2025 Exploring facial expression processing with fast periodic visual stimulation and diverse stimuli. Brain and Cognition. 2025; doi:10.1016/j.bandc.2025.106338.</p> </li> <li> <p>Vandenheever et. al, 2025. Preliminary evidence for anxiety linked neural sensitivity to emotional faces using fast periodic visual stimulation. International Journal of Psychophysiology. doi: 10.1016/j.ijpsycho.2025.113212.</p> </li> <li> <p>Rossion B, Torfs K, Jacques C, Liu-Shuang J. Fast periodic presentation of natural images reveals a robust face-selective electrophysiological response in the human brain. J Vis. 2015;15(1):15.1.18. Published 2015 Jan 16. doi:10.1167/15.1.18</p> </li> <li> <p>Rossion B, Retter TL, Liu-Shuang J. Understanding human individuation of unfamiliar faces with oddball fast periodic visual stimulation and electroencephalography. Eur J Neurosci. 2020;52(10):4283-4344. doi:10.1111/ejn.14865</p> </li> </ul> <p>These papers provide the main conceptual and analytical background for FPVS paradigms, oddball designs, and harmonic-based frequency-tagging analyses used in the Toolbox.</p>"},{"location":"relevant-publications/#eeg-erp-methods-and-preprocessing","title":"EEG / ERP Methods and Preprocessing","text":"<ul> <li> <p>Gil \u00c1vila, C., Bott, F.S., Tiemann, L. et al. DISCOVER-EEG: an open, fully automated EEG pipeline for biomarker discovery in clinical neuroscience. Sci Data 10, 613 (2023). https://doi.org/10.1038/s41597-023-02525-0</p> </li> <li> <p>Hern\u00e1ndez-Mustieles, M. A., Lima-Carmona, Y. E., Mendoza-Armenta, A. A., Hernandez-Machain, X., Garza-V\u00e9lez, D. A., Carrillo-M\u00e1rquez, A., Rodr\u00edguez-Alvarado, D. C., Lozoya-Santos, J. d. J., &amp; Ram\u00edrez-Moreno, M. A. (2024). An EEG Dataset of Subject Pairs during Collaboration and Competition Tasks in Face-to-Face and Online Modalities. Data, 9(4), 47. https://doi.org/10.3390/data9040047</p> </li> </ul> <p>These references give general foundations for EEG/ERP recording, artifact handling, filtering, referencing, and statistical analysis that inform the preprocessing pipeline.</p>"},{"location":"relevant-publications/#statistical-methods-and-linear-mixed-models","title":"Statistical Methods and Linear Mixed Models","text":"<ul> <li> <p>Boisgontier MP, Cheval B. The anova to mixed model transition. Neurosci Biobehav Rev. 2016;68:1004-1005. doi:10.1016/j.neubiorev.2016.05.034</p> </li> <li> <p>Matuschek, Hannes &amp; Kliegl, Reinhold &amp; Vasishth, Shravan &amp; Baayen, Harald &amp; Bates, Douglas. (2017). Balancing Type I Error and Power in Linear Mixed Models. Journal of Memory and Language. 94. 305\u2013315. 10.1016/j.jml.2017.01.001. </p> </li> <li> <p>Heise MJ, Mon SK, Bowman LC. Utility of linear mixed effects models for event-related potential research with infants and children. Dev Cogn Neurosci. 2022;54:101070. doi:10.1016/j.dcn.2022.101070</p> </li> </ul> <p>These works underpin the use of Benjamini\u2013Hochberg FDR correction and linear mixed-effects models for the statistical outputs generated by the FPVS Toolbox.</p>"},{"location":"relevant-publications/#how-to-cite-the-fpvs-toolbox","title":"How to Cite the FPVS Toolbox","text":"<p>If you use the FPVS Toolbox in a publication, please consider citing:</p> <p>Murphy Z., et al. FPVS Toolbox: Automated preprocessing and statistical analysis for fast periodic visual stimulation EEG experiments. [Manuscript in preparation / preprint details to be added here.]</p> <p>Update this section with the final reference once a preprint or paper is available.</p>"},{"location":"statistical-analysis/","title":"Statistical Analysis","text":"<p>This page summarizes the statistical methods used by the FPVS Toolbox Statistical Analysis module for end users. It focuses on the primary output measure (Summed BCA) and how to interpret results in the single-group and multi-group workflows.</p>"},{"location":"statistical-analysis/#how-the-methods-work-together-high-level","title":"How the methods work together (high-level)","text":"<ol> <li>Summed BCA DV is defined from the ROI-aggregated spectral outputs.</li> <li>Harmonics are selected (e.g., Rossion method) to decide which    oddball harmonics contribute to the DV.</li> <li>A subject \u00d7 condition \u00d7 ROI table of Summed BCA values is built.</li> <li>RM-ANOVA and/or a linear mixed-effects model summarize    condition, ROI, and interaction effects.</li> <li>Post-hoc paired t-tests (within each ROI) follow a significant    interaction to explain which condition pairs differ.</li> </ol> <p>Interpretation guide (single-group):</p> <ul> <li>Overall response present: Summed BCA values are consistently above   zero and/or the mixed-model intercept is positive. Note that RM-ANOVA   tests differences among conditions and ROIs; it does not directly test   DV vs 0 (Not found in code: an explicit one-sample test on Summed BCA   within the main RM-ANOVA pipeline). See \u201cNot found in code\u201d notes below.</li> <li>Condition main effect: responses differ across experimental   conditions (averaged across ROIs).</li> <li>ROI main effect: responses differ across ROIs (averaged across   conditions).</li> <li>Condition \u00d7 ROI interaction: the condition effect depends on which   ROI is considered.</li> </ul> <p>Cautions:</p> <ul> <li>Multiple comparisons: post-hoc tests are corrected for false   discovery rate; still interpret effect sizes and confidence intervals.</li> <li>Harmonic sets can differ by ROI (Rossion method). This can make ROI   differences partly reflect different harmonic selections.</li> <li>Assumptions: check normality and sphericity (RM-ANOVA) and residual   diagnostics (mixed model) as part of reporting.</li> </ul>"},{"location":"statistical-analysis/#summed-bca-dv-and-harmonic-selection","title":"Summed BCA DV and harmonic selection","text":"<p>The DV used for statistical analysis is the Summed baseline-corrected oddball amplitude (Summed BCA). It is computed per subject \u00d7 condition \u00d7 ROI by summing BCA across selected oddball harmonics and then averaging across ROI channels.</p> <ul> <li>Source data: The DV is computed from the \u201cBCA (uV)\u201d sheet in the   spectral/ROI output file; Z-score information used for harmonic   selection comes from the \u201cZ Score\u201d sheet.</li> <li>ROI aggregation: The ROI mean is computed after summing selected   harmonics for each channel within the ROI.</li> </ul> <p>For detailed harmonic selection rules (Rossion method), see: Rossion harmonic selection.</p>"},{"location":"statistical-analysis/#single-group-analyses","title":"Single-group analyses","text":""},{"location":"statistical-analysis/#repeated-measures-anova-rm-anova","title":"Repeated-measures ANOVA (RM-ANOVA)","text":"<ul> <li>Within-subject factors: Condition and ROI (plus their interaction).</li> <li>Implementation:</li> <li>Primary path: Pingouin <code>rm_anova</code> (detailed table when available,     including Greenhouse\u2013Geisser and Huynh\u2013Feldt corrections).</li> <li>Fallback: statsmodels <code>AnovaRM</code> if Pingouin is not available.</li> <li>Outputs: F statistic, numerator/denominator degrees of freedom,   p-values, and partial eta-squared effect sizes.</li> </ul> <p>Interpretation:</p> <ul> <li>F statistic: ratio of variance explained by the effect to residual   variance (larger F \u2192 stronger evidence for an effect).</li> <li>df1/df2: numerator/denominator degrees of freedom for the effect.</li> <li>GG/HF corrections: appear when Pingouin can compute sphericity   corrections.</li> </ul> <p>For more details, see: RM-ANOVA details.</p>"},{"location":"statistical-analysis/#post-hoc-tests-interaction-breakdown","title":"Post-hoc tests (interaction breakdown)","text":"<ul> <li>Paired t-tests between all condition pairs, run separately   within each ROI.</li> <li>Correction: Benjamini\u2013Hochberg FDR within each ROI (i.e., each   ROI\u2019s condition-pair family is corrected independently).</li> <li>Effect size: Cohen\u2019s dz for paired samples, based on the   subject-wise condition differences.</li> </ul> <p>For more details, see: Post-hoc tests.</p>"},{"location":"statistical-analysis/#linear-mixed-effects-model-single-group","title":"Linear mixed-effects model (single group)","text":"<ul> <li>Library: statsmodels <code>MixedLM</code>.</li> <li>Fixed effects: condition, ROI, and condition \u00d7 ROI interaction.</li> <li>Random effects: random intercept for subject.</li> <li>Coding: condition and ROI are sum-coded by default when present   (no explicit coding is set for other factors).</li> </ul> <p>For more details, see: Mixed model details.</p>"},{"location":"statistical-analysis/#multi-group-analyses","title":"Multi-group analyses","text":"<p>Multi-group mode compares two or more groups (e.g., clinical vs control).</p>"},{"location":"statistical-analysis/#between-group-anova-mixed-anova","title":"Between-group ANOVA (mixed ANOVA)","text":"<ul> <li>Factors: Group (between-subjects) \u00d7 Condition (within-subjects).</li> <li>DV: Summed BCA, typically collapsed across ROI for this test.</li> <li>Implementation: Pingouin <code>mixed_anova</code> is required; the fallback   does not support a between-group factor.</li> </ul>"},{"location":"statistical-analysis/#between-group-mixed-model","title":"Between-group mixed model","text":"<ul> <li>Fixed effects: group, condition, ROI, and all interactions.</li> <li>Random effects: random intercept for subject.</li> </ul>"},{"location":"statistical-analysis/#group-contrasts","title":"Group contrasts","text":"<ul> <li>Welch\u2019s t-tests (unequal variances) for each   condition \u00d7 ROI combination.</li> <li>Correction: Benjamini\u2013Hochberg FDR across all contrasts in the   output table.</li> <li>Effect size: Cohen\u2019s d for independent groups.</li> </ul>"},{"location":"statistical-analysis/#outliers-qc-flags-and-manual-exclusions","title":"Outliers, QC flags, and manual exclusions","text":"<p>The Stats tool can generate QC and DV flags and separate them from manual exclusions. See Outliers and QC for details.</p>"},{"location":"statistical-analysis/#output-files","title":"Output files","text":"<ul> <li>Results are written to the project\u2019s \u201c3 - Statistical Analysis   Results\u201d folder.</li> <li>Common exports include:</li> <li>RM-ANOVA tables.</li> <li>Mixed-model fixed-effects tables.</li> <li>Post-hoc tables with raw and FDR-adjusted p-values plus effect sizes.</li> <li>Rossion DV definition export (when using Rossion selection).</li> <li>Flagged and excluded participant reports (if QC/outlier checks are     enabled).</li> </ul>"},{"location":"statistical-analysis/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>An explicit one-sample test against zero as part of the RM-ANOVA   pipeline. (Searched in <code>src/Tools/Stats/PySide6/stats_workers.py</code>,   <code>src/Tools/Stats/Legacy/stats_analysis.py</code>, and   <code>src/Tools/Stats/Legacy/repeated_m_anova.py</code>.)</li> </ul>"},{"location":"tutorial/","title":"FPVS Toolbox: Getting Started","text":"<ol> <li>First, download the FPVS Toolbox installer from the latest release on github. Follow all instructions. You may have to manually bypass Windows Defender or other antivirus software.</li> </ol> <p>The rest of the FPVS Toolbox tutorial will be added soon. </p>"},{"location":"statistics/mixed-model/","title":"Linear mixed-effects model (Summed BCA)","text":"<p>The FPVS Toolbox provides a linear mixed-effects model (LMM) for Summed BCA, allowing you to model repeated measures within subjects while estimating condition/ROI effects.</p>"},{"location":"statistics/mixed-model/#implementation","title":"Implementation","text":"<ul> <li>Library: statsmodels <code>MixedLM</code>.</li> <li>Random effects: random intercept for each subject (default).</li> <li>Fixed effects (single group): condition, ROI, and their interaction.</li> <li>Fixed effects (multi-group): group, condition, ROI, and all   interactions.</li> </ul>"},{"location":"statistics/mixed-model/#coding-of-categorical-variables","title":"Coding of categorical variables","text":"<ul> <li>Condition and ROI are sum-coded by default when present.</li> <li>Group coding: Not found in code. The model does not explicitly set   group contrasts, so statsmodels\u2019 default coding likely applies.</li> </ul>"},{"location":"statistics/mixed-model/#how-to-interpret-coefficients","title":"How to interpret coefficients","text":"<ul> <li>Intercept: average Summed BCA across all conditions/ROIs (and   groups, if using sum coding). A positive intercept suggests an overall   response above zero.</li> <li>Condition terms: how each condition deviates from the overall mean   (under sum coding).</li> <li>ROI terms: how each ROI deviates from the overall mean.</li> <li>Interaction terms: whether condition effects differ by ROI (or by   group in multi-group mode).</li> </ul>"},{"location":"statistics/mixed-model/#relationship-to-rm-anova","title":"Relationship to RM-ANOVA","text":"<ul> <li>RM-ANOVA is the traditional repeated-measures approach (balanced   designs, sphericity corrections).</li> <li>Mixed model provides a flexible alternative that can handle some   missing data (after exclusions) and gives coefficient-level estimates.</li> </ul>"},{"location":"statistics/mixed-model/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>A user-facing toggle to enable random slopes or likelihood-ratio tests   (the helper supports these, but the Stats tool calls it with random   intercept only and no LRTs). (Searched in   <code>src/Tools/Stats/Legacy/mixed_effects_model.py</code> and   <code>src/Tools/Stats/PySide6/stats_workers.py</code>.)</li> </ul>"},{"location":"statistics/outliers-and-qc/","title":"Outliers, QC flags, and manual exclusions","text":"<p>The Statistical Analysis module separates flags (informational) from exclusions (participants actually removed from analysis). This lets you review QC warnings before deciding whether to exclude anyone.</p>"},{"location":"statistics/outliers-and-qc/#what-is-flagged-vs-excluded","title":"What is flagged vs. excluded","text":""},{"location":"statistics/outliers-and-qc/#qc-flags-informational","title":"QC flags (informational)","text":"<ul> <li>QC screening examines all conditions and ROIs in the project, even   if you later select a subset for analysis.</li> <li>QC uses robust thresholds on sum(|BCA|) and max(|BCA|) metrics   (across oddball harmonics) to flag unusually large responses.</li> <li>QC flags do not automatically remove participants. They appear in   the Flagged Participants report so you can review them.</li> </ul>"},{"location":"statistics/outliers-and-qc/#dv-hard-limit-flags-informational","title":"DV hard-limit flags (informational)","text":"<ul> <li>A hard DV limit (absolute value) flags participants whose Summed   BCA values exceed the limit.</li> <li>These are also flags only unless the value is non-finite.</li> </ul>"},{"location":"statistics/outliers-and-qc/#required-exclusions-automatic","title":"Required exclusions (automatic)","text":"<ul> <li>Participants with non-finite Summed BCA values are required   exclusions and are removed from analyses.</li> </ul>"},{"location":"statistics/outliers-and-qc/#manual-exclusions-user-controlled","title":"Manual exclusions (user-controlled)","text":"<ul> <li>You can manually select participants to exclude. This is the only   user-controlled exclusion step.</li> <li>Manual exclusions are applied before analyses run.</li> </ul>"},{"location":"statistics/outliers-and-qc/#where-to-find-the-reports","title":"Where to find the reports","text":"<p>Exports live in \u201c3 - Statistical Analysis Results\u201d and include:</p> <ul> <li>Flagged Participants.xlsx</li> <li>Flag Summary and Flag Details tabs for QC and DV flags.</li> <li>Excluded Participants.xlsx</li> <li>Records manual exclusions and required non-finite exclusions.</li> </ul>"},{"location":"statistics/outliers-and-qc/#interpretation-tips","title":"Interpretation tips","text":"<ul> <li>Use Flagged Participants.xlsx to document quality concerns and   justify any manual exclusions in your reporting.</li> <li>Because QC flags do not remove participants automatically, the   final sample size depends on manual exclusions plus required   non-finite exclusions.</li> </ul>"},{"location":"statistics/outliers-and-qc/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>A setting to automatically exclude QC-flagged participants. (Searched   in <code>src/Tools/Stats/PySide6/stats_workers.py</code> and   <code>src/Tools/Stats/PySide6/stats_outlier_exclusion.py</code>.)</li> </ul>"},{"location":"statistics/posthoc-tests/","title":"Post-hoc tests (interaction breakdown)","text":"<p>Post-hoc tests are run after an interaction is found in RM-ANOVA. They explain which condition pairs differ within each ROI.</p>"},{"location":"statistics/posthoc-tests/#what-is-tested","title":"What is tested","text":"<ul> <li>Within each ROI, the tool runs paired t-tests for every pair of   conditions.</li> <li>The analysis is within-subject, so each test uses subject-wise   differences between the two conditions.</li> </ul>"},{"location":"statistics/posthoc-tests/#multiple-comparison-correction","title":"Multiple-comparison correction","text":"<ul> <li>Correction method: Benjamini\u2013Hochberg FDR (<code>fdr_bh</code>).</li> <li>Correction family: applied within each ROI (all condition-pair   tests for that ROI are corrected together).</li> </ul>"},{"location":"statistics/posthoc-tests/#effect-sizes-and-outputs","title":"Effect sizes and outputs","text":"<p>Each pairwise result includes:</p> <ul> <li>t statistic and p-value (raw and FDR-adjusted).</li> <li>Cohen\u2019s dz (paired-samples effect size), computed as mean difference   divided by the standard deviation of paired differences.</li> <li>Mean difference (Condition A \u2212 Condition B) and 95% CI.</li> <li>Shapiro p-value for paired differences (informational only).</li> </ul> <p>Interpretation tips:</p> <ul> <li>Direction: a positive mean difference means Condition A &gt; Condition   B for Summed BCA.</li> <li>Effect size (dz): larger absolute values indicate stronger   condition differences within the ROI.</li> </ul>"},{"location":"statistics/posthoc-tests/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>A user-facing setting to change the post-hoc correction method from   Benjamini\u2013Hochberg FDR to another option. (Searched in   <code>src/Tools/Stats/Legacy/posthoc_tests.py</code> and   <code>src/Tools/Stats/PySide6/stats_workers.py</code>.)</li> </ul>"},{"location":"statistics/rm-anova/","title":"RM-ANOVA details (Summed BCA)","text":"<p>The FPVS Toolbox uses repeated-measures ANOVA (RM-ANOVA) to test within-subject effects of Condition, ROI, and their interaction on Summed BCA.</p>"},{"location":"statistics/rm-anova/#implementation","title":"Implementation","text":"<ul> <li>Primary library: Pingouin <code>rm_anova</code> (when installed).</li> <li>Fallback library: statsmodels <code>AnovaRM</code> (when Pingouin is not   available).</li> </ul> <p>The output is normalized into a consistent table that includes:</p> <ul> <li>Effect (Condition, ROI, Condition \u00d7 ROI)</li> <li>F Value (F statistic)</li> <li>Num DF / Den DF (degrees of freedom)</li> <li>Pr &gt; F (p-value)</li> <li>partial eta squared (effect size)</li> <li>Pr &gt; F (GG) and Pr &gt; F (HF) when Pingouin provides sphericity   corrections</li> </ul>"},{"location":"statistics/rm-anova/#how-to-read-the-table","title":"How to read the table","text":"<ul> <li>F statistic: ratio of explained variance to residual variance. A   larger F indicates stronger evidence for an effect.</li> <li>Num DF / Den DF: degrees of freedom for the effect and error.</li> <li>p-values: use the GG/HF corrected columns when available (they   adjust for sphericity violations).</li> <li>partial eta squared: effect size, computed from F and dfs when not   provided by the library.</li> </ul>"},{"location":"statistics/rm-anova/#notes-for-end-users","title":"Notes for end users","text":"<ul> <li>RM-ANOVA requires a balanced design (each subject must have all   required condition \u00d7 ROI combinations). If the data are unbalanced, the   analysis reports an error and lists missing combinations.</li> <li>RM-ANOVA focuses on differences among conditions and ROIs; it does   not directly test whether Summed BCA is different from zero.</li> </ul>"},{"location":"statistics/rm-anova/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>A user-facing setting that toggles sphericity correction methods   (Pingouin decides this internally). (Searched in   <code>src/Tools/Stats/Legacy/repeated_m_anova.py</code> and   <code>src/Tools/Stats/PySide6/stats_main_window.py</code>.)</li> </ul>"},{"location":"statistics/rossion-harmonic-selection/","title":"Rossion harmonic selection (Summed BCA)","text":"<p>This page explains the Rossion method used to define which oddball harmonics contribute to the Summed BCA DV. The method is ROI-specific and is based on group mean Z-scores computed from the Z-score sheet in your spectral output files.</p>"},{"location":"statistics/rossion-harmonic-selection/#what-the-method-produces","title":"What the method produces","text":"<p>For each ROI, the Rossion method produces a list of oddball harmonics (Hz). That list is then used to compute Summed BCA for every subject and every condition in that ROI.</p> <ul> <li>Per ROI: each ROI gets its own selected harmonic set.</li> <li>Per subject \u00d7 condition \u00d7 ROI: Summed BCA is the sum of BCA values   over those selected harmonics, averaged across channels in the ROI.</li> </ul>"},{"location":"statistics/rossion-harmonic-selection/#inputs-and-data-sources","title":"Inputs and data sources","text":"<p>The Rossion method uses the same per-subject, per-condition Excel output files that store ROI-aggregated spectral data.</p> <ul> <li>Z-score source: the \u201cZ Score\u201d sheet is used to compute group mean   Z-values for each ROI and harmonic.</li> <li>BCA source: the \u201cBCA (uV)\u201d sheet provides the BCA amplitudes to   be summed once harmonics are selected.</li> <li>Column format: frequency bins are read from columns that end in   <code>_Hz</code> (e.g., <code>1.2_Hz</code>).</li> </ul>"},{"location":"statistics/rossion-harmonic-selection/#step-1-build-the-candidate-harmonic-domain","title":"Step 1: Build the candidate harmonic domain","text":"<p>The tool builds the candidate harmonic list using the following steps:</p> <ol> <li>Read frequency columns from the Z-score sheet (columns ending in    <code>_Hz</code>).</li> <li>Exclude base-rate harmonics: any column that is an exact multiple    of the base frequency is removed (tolerance 1e-6).</li> <li>Select oddball harmonics: oddball harmonics are defined as    multiples of (base frequency / every_n), with the default    <code>every_n = 5</code> and tolerance 1e-3.</li> <li>Optional exclusion of harmonic 1: if \u201cExclude harmonic 1\u201d is    enabled, harmonic number 1 is removed from the list.</li> </ol> <p>Result: an ordered list of oddball harmonic frequencies (Hz) that are candidates for the Rossion selection rule.</p>"},{"location":"statistics/rossion-harmonic-selection/#step-2-compute-group-mean-z-per-roi-and-harmonic","title":"Step 2: Compute group mean Z per ROI and harmonic","text":"<p>For each subject, condition, ROI, and harmonic in the domain:</p> <ul> <li>The tool averages Z values across the ROI\u2019s channels (using the   channels that are present in the Z-score sheet).</li> <li>These ROI-mean Z values are pooled across all selected conditions and   all subjects, then averaged to yield a group mean Z for each   ROI \u00d7 harmonic.</li> </ul> <p>This produces a table with columns like:</p> <ul> <li><code>roi</code></li> <li><code>harmonic_hz</code></li> <li><code>mean_z</code> (group mean Z across selected conditions and subjects)</li> </ul>"},{"location":"statistics/rossion-harmonic-selection/#step-3-rossion-selection-rule-per-roi","title":"Step 3: Rossion selection rule (per ROI)","text":"<p>For each ROI, harmonics are scanned in ascending order:</p> <ul> <li>Threshold: a harmonic is significant if group mean Z exceeds the   current Z threshold (default 1.64). The threshold is set in the   Statistical Analysis settings.</li> <li>Arm after first significant: non-significant harmonics are ignored   until the first significant harmonic is found.</li> <li>Stop rule: after the first significant harmonic is found, the   algorithm stops after 2 consecutive non-significant harmonics.</li> </ul> <p>The selected harmonics are the significant harmonics before the stop rule triggers.</p>"},{"location":"statistics/rossion-harmonic-selection/#step-4-compute-summed-bca-the-dv","title":"Step 4: Compute Summed BCA (the DV)","text":"<p>For each subject \u00d7 condition \u00d7 ROI:</p> <ol> <li>Read BCA (uV) values at the selected harmonics for that ROI.</li> <li>Sum BCA across selected harmonics for each channel in the ROI.</li> <li>Average across ROI channels to yield the Summed BCA value.</li> </ol> <p>This produces the DV table used by RM-ANOVA, mixed models, and post-hoc comparisons.</p>"},{"location":"statistics/rossion-harmonic-selection/#fallback-behavior-when-no-harmonics-are-selected","title":"Fallback behavior when no harmonics are selected","text":"<p>If the Rossion method selects no harmonics for a given ROI, the behavior depends on the Empty list policy setting:</p> <ul> <li>Fallback to Fixed-K (default): use the Fixed-K selection (default   K = 5) instead of the empty list.</li> <li>Set DV = 0: keep the harmonic list empty and set Summed BCA to 0   for that ROI.</li> <li>Error: stop and report an error so you can adjust settings.</li> </ul> <p>The Fixed-K harmonics are also built from oddball harmonics (every_n = 5) and can optionally exclude harmonic 1 and base-rate harmonics.</p>"},{"location":"statistics/rossion-harmonic-selection/#outputs-you-can-review","title":"Outputs you can review","text":"<p>When you export results after running the Rossion method, the tool writes Summed BCA DV Definition.xlsx with:</p> <ul> <li>DV Definition (summary of the policy and thresholds),</li> <li>ROI Harmonics (selected harmonics per ROI, fallback use, stop   reason),</li> <li>Mean Z Table (group mean Z values used for selection).</li> </ul>"},{"location":"statistics/rossion-harmonic-selection/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>A user-facing description of how Z thresholds are labeled in the UI   beyond \u201cminimum group-mean Z value for a harmonic to count as   significant.\u201d (Searched in <code>src/Tools/Stats/PySide6/stats_main_window.py</code>   and <code>src/Tools/Stats/PySide6/dv_policies.py</code>.)</li> </ul>"}]}