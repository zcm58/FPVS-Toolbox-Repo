{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"FPVS Toolbox Documentation","text":"<p>The Fast Periodic Visual Stimulation (FPVS) Toolbox allows you to easily process EEG data from FPVS experiments and run statistical analyses on the resulting metrics. As of now, FPVS Toolbox only supports the BioSemi data format (.BDF) and FPVS experiments ran with PsychoPy. </p> <p>This documentation page is a work in progress and is not yet complete.</p> <p>Current app version: v1.5.0</p>"},{"location":"#quick-start","title":"Quick start","text":"<ol> <li>Install FPVS Toolbox    Download the latest installer from the GitHub Releases page and run it    on Windows. You may have to bypass Windows Defender if prompted. When you run FPVS Toolbox for the first time, you    will be asked to select a \"Project Root\". This is where all the different results from various projects you create    within FPVS Toolbox will live. I recommend that you avoid using cloud based folders like OneDrive - it sometimes    causes issues with Statistical Analysis. </li> </ol> <ol> <li>Create or open a project </li> </ol> <p>From the main window, choose \"Create New Project\". You will be prompted to title your project, select the number of experimental groups, and to name each group. Next, you will select the input folder for each group (wherever you have stored your .BDF files).</p> <p>You will need to input titles for each FPVS Condition in your experiment in the Main App GUI, as well as the     PsychoPy trigger code associated with that condition. </p> <ol> <li>Process EEG data </li> <li>Select an EEG file or batch folder.  </li> <li>Configure preprocessing (reference, downsampling, filters, artifact      handling) in the Settings panel.  </li> <li> <p>Click Start Processing to run the pipeline and generate metrics      and Excel outputs.</p> </li> <li> <p>Run statistical analysis</p> </li> <li> <p>Open Statistical Analysis in the sidebar to run single-group or    between-group analyses on the processed data.</p> </li> </ol>"},{"location":"#core-documentation","title":"Core documentation","text":"<ul> <li> <p>Processing Pipeline   Detailed description of how recordings are loaded, preprocessed, epoched,   and converted to frequency-domain metrics.</p> </li> <li> <p>Statistical Analysis   Overview of single-group and between-group analyses, models used, and   how to interpret the outputs.</p> </li> <li> <p>Relevant Publications   A brief overview of relevant publications on FPVS and the preprocessing pipeline used inside the FPVS Toolbox. </p> </li> <li> <p>Tutorials &amp; Walkthroughs   Step-by-step examples on how to use the FPVS Toolbox.</p> </li> </ul>"},{"location":"#project-links","title":"Project links","text":"<ul> <li>GitHub repository: <code>https://github.com/zcm58/FPVS-Toolbox-Repo&gt;</code></li> </ul>"},{"location":"processing-pipeline/","title":"Processing Pipeline","text":"<p>This page describes the single-file processing pipeline used by FPVS Toolbox. It is written for end users who need manuscript-ready Methods text and verified implementation details.</p>"},{"location":"processing-pipeline/#manuscript-ready-summary-copypaste","title":"Manuscript-ready summary (copy/paste)","text":"<p>The FPVS Toolbox processes EEG recordings stored as BioSemi .bdf files using MNE-Python for loading, channel typing, and preprocessing. For each recording, the toolbox loads data with disk-backed memory mapping when available, assigns channel types (including a configured stimulus/trigger channel), and applies a standard 10\u201310 montage. Preprocessing follows a fixed sequence: initial re-reference to a user-specified pair of electrodes (default EXG1 and EXG2),  removal of those EXG channels, optional channel-count limiting, optional downsampling,  zero-phase FIR bandpass filtering, kurtosis-based bad-channel detection with interpolation,  and a final average re-reference. Events are extracted from the stim channel then epochs are created  for each user-defined condition label using a configured time window without baseline  correction. The time-domain data are averaged across epochs per condition,  transformed with an FFT, and  frequency-domain metrics are computed at the target oddball  harmonics (SNR, baseline-corrected amplitude, and Z-score). Results are exported to  per-condition Excel files (electrode-level metrics and a full-spectrum SNR sheet), which  serve as inputs for ROI aggregation and statistical analyses in the Stats tool.</p> <p>Parameter placeholders: Use the processing log and project settings/manifest (exported from the UI) to fill in your actual values for reference channels, filters, epoch window, and oddball frequency settings.</p>"},{"location":"processing-pipeline/#single-file-pipeline-verified-order","title":"Single-file pipeline (verified order)","text":"<p>The steps below reflect the linear processing order for one recording file as implemented in the current codebase. \u201cImplementation verified in:\u201d notes point you to the exact modules that define each step.</p>"},{"location":"processing-pipeline/#1-data-import-file-loading","title":"1) Data import / file loading","text":"<p>What happens</p> <ul> <li>Supported input types: <code>.bdf</code> (BioSemi). Other formats   are rejected. (Implementation verified in: <code>src/Main_App/PySide6_App/Backend/loader.py</code>.)</li> <li>Disk-backed memory mapping: the loader requests a disk-backed <code>preload</code> path   for <code>.bdf</code> and (when supported) <code>.set</code> files, then materializes the memmap with   <code>raw.load_data()</code> to keep RAM use bounded. (Implementation verified in:   <code>src/Main_App/PySide6_App/Backend/loader.py</code>.)</li> <li>Channel typing policy:</li> <li>The stimulus/trigger channel is explicitly typed as <code>stim</code>.</li> <li>The reference pair (e.g., EXG1/EXG2) is preserved as <code>eeg</code> so it can be     used for re-referencing.</li> <li>Other EXG channels (EXG1\u2013EXG8 not in the reference pair) are demoted to     <code>misc</code>.   (Implementation verified in: <code>src/Main_App/PySide6_App/Backend/loader.py</code>.)</li> <li>Montage: a standard 10\u201320 montage (<code>standard_1020</code>) is applied with   <code>on_missing=\"warn\"</code> and case-insensitive matching. (Implementation verified in:   <code>src/Main_App/PySide6_App/Backend/loader.py</code>.)</li> </ul> <p>Key parameters</p> Parameter Default Source Notes <code>stim_channel</code> <code>Status</code> Project settings / global settings Used for event detection and typed as <code>stim</code>. <code>ref_channel1</code>, <code>ref_channel2</code> <code>EXG1</code>, <code>EXG2</code> Project settings / global settings Kept as <code>eeg</code> during loading. <p>(Defaults verified in: <code>src/Main_App/PySide6_App/Backend/loader.py</code>, <code>src/Main_App/PySide6_App/Backend/preprocessing_settings.py</code>.)</p>"},{"location":"processing-pipeline/#2-preprocessing-fixed-order","title":"2) Preprocessing (fixed order)","text":"<p>Preprocessing is applied in a fixed sequence. Each operation is optional only if its parameter is unset/disabled.</p> <p>Fixed order (implementation verified in <code>src/Main_App/PySide6_App/Backend/preprocess.py</code>):</p> <ol> <li>Initial re-reference to the user-selected EXG pair (if both channels are    present). The reference pair is applied using <code>raw.set_eeg_reference(...)</code>.</li> <li>Drop reference channels: the two reference channels are removed from the    data after re-referencing.</li> <li>Optional channel limit: if <code>max_idx_keep</code> is set and smaller than the    current channel count, only the first N channels are retained plus the    stim channel (if present).</li> <li>Optional downsampling: if <code>downsample_rate</code> is set and lower than the    current sampling rate, the data are resampled with a Hann window.</li> <li>FIR bandpass filter (zero-phase, forward/backward):</li> <li>Method: <code>fir</code> with <code>firwin</code> design, <code>hamming</code> window, <code>phase=\"zero-double\"</code>.</li> <li>Transition bandwidths: 0.1 Hz (low and high).</li> <li>Fixed filter length: 8449 points.</li> <li>Kurtosis-based bad-channel detection &amp; interpolation:</li> <li>Kurtosis (Fisher, <code>bias=False</code>) is computed per EEG channel.</li> <li>A trimmed mean/std is computed by removing 10% of the highest and lowest      kurtosis values.</li> <li>Channels with <code>|z| &gt; rejection_z</code> are marked bad.</li> <li>If a montage is present, bad channels are interpolated      (<code>reset_bads=True</code>, <code>mode=\"accurate\"</code>).</li> <li>Final average reference: average reference is applied via projection and    immediately applied (<code>apply_proj</code>).</li> </ol> <p>Key parameters (defaults)</p> Parameter Default Purpose <code>high_pass</code> 0.1 Hz High-pass cutoff (HPF) <code>low_pass</code> 50.0 Hz Low-pass cutoff (LPF) <code>downsample</code> / <code>downsample_rate</code> 256 Hz Target sampling rate <code>rejection_z</code> / <code>reject_thresh</code> 5.0 Kurtosis Z threshold <code>max_idx_keep</code> 64 Max channel index to keep <code>ref_channel1</code>, <code>ref_channel2</code> EXG1 / EXG2 Initial reference pair <p>(Defaults verified in: <code>src/Main_App/PySide6_App/Backend/preprocessing_settings.py</code>.)</p> <p>Logged/audited items</p> <ul> <li>A preprocessing fingerprint string (HP/LP/downsample/reject/ref/stim).</li> <li>Filter snapshot (computed cutoffs and sampling rate).</li> <li>Number of bad channels rejected by kurtosis.</li> <li>Final sampling rate and channel count.</li> </ul> <p>(Logging verified in: <code>src/Main_App/PySide6_App/Backend/preprocess.py</code>.)</p>"},{"location":"processing-pipeline/#3-event-detection-and-condition-mapping","title":"3) Event detection and condition mapping","text":"<p>Event detection (single-file pipeline)</p> <ul> <li>The toolbox attempts to read events from the configured stim channel using   <code>mne.find_events(...)</code>.</li> <li>If stim-based extraction fails, it falls back to   <code>mne.events_from_annotations(...)</code>.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Performance/process_runner.py</code>.)</p> <p>Condition mapping</p> <ul> <li>Your Event Map supplies <code>label \u2192 integer code</code> pairs.</li> <li>For each label, events are included only if that integer code is present in   the extracted events.</li> <li>If a label has zero matching events, the pipeline logs a warning and skips   that label for the file.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Performance/process_runner.py</code>.)</p>"},{"location":"processing-pipeline/#4-epoching","title":"4) Epoching","text":"<ul> <li>Epochs are created per label with:</li> <li><code>tmin = epoch_start</code> and <code>tmax = epoch_end</code> (seconds)</li> <li><code>baseline = None</code> (no baseline correction at epoch stage)</li> <li><code>preload = False</code></li> <li><code>decim = 1</code></li> <li>After creation, <code>epochs.drop_bad()</code> is called.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Performance/process_runner.py</code>.)</p> <p>Not found in code; user-configurable / unknown</p> <ul> <li>Epoch rejection thresholds (e.g., voltage limits): no explicit <code>reject</code>   or <code>flat</code> criteria are passed to <code>mne.Epochs</code>. Search locations:</li> <li><code>src/Main_App/Performance/process_runner.py</code> (keywords: <code>Epochs</code>, <code>reject</code>, <code>flat</code>)</li> <li><code>src/Main_App/Legacy_App/processing_utils.py</code> (keywords: <code>Epochs</code>, <code>reject</code>, <code>flat</code>)</li> </ul>"},{"location":"processing-pipeline/#5-frequency-domain-analysis-fft","title":"5) Frequency-domain analysis (FFT)","text":"<ul> <li>For each condition, epochs are averaged in the time domain and the FFT is   computed on the averaged signal (not per-epoch).</li> <li>FFT uses <code>np.fft.fft</code> with no explicit windowing, detrending, or zero-padding.</li> <li>The amplitude spectrum is computed as:   <code>abs(FFT) / N * 2</code> for bins from 0 to Nyquist.</li> <li>Frequency bins are linearly spaced from 0 to <code>sfreq / 2</code>.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Legacy_App/post_process.py</code>.)</p>"},{"location":"processing-pipeline/#6-metric-computation-snr-bca-z-score","title":"6) Metric computation (SNR, BCA, Z-score)","text":"<p>Target frequencies</p> <ul> <li>The toolbox computes metrics at oddball harmonics defined by   <code>TARGET_FREQUENCIES</code>.</li> <li>These are calculated as: <code>oddball_freq \u00d7 1..K</code>, where   <code>K = round(bca_upper_limit / oddball_freq)</code>.</li> <li><code>oddball_freq</code> and <code>bca_upper_limit</code> come from project settings.</li> </ul> <p>(Implementation verified in: <code>src/config.py</code>.)</p> <p>Noise window and baseline definition (used by SNR, BCA, Z)</p> <p>For each target frequency, the toolbox finds the nearest FFT bin and defines noise bins as follows:</p> <ul> <li>Window: \u00b110 bins around the target bin.</li> <li>Exclusions: target bin and its immediate neighbors (\u22121 and +1) are excluded.</li> <li>Minimum bins: if fewer than 4 candidate bins remain, noise mean/std are set   to 0.0.</li> <li>Trimming: one maximum and one minimum value are removed before computing the   mean and standard deviation.</li> <li>Standard deviation uses population variance (<code>ddof=0</code>).</li> </ul> <p>(Implementation verified in: <code>src/Tools/Stats/Legacy/noise_utils.py</code> and <code>src/Main_App/Legacy_App/post_process.py</code>.)</p> <p>Formulas (applied per channel \u00d7 harmonic)</p> <p>Let: - <code>A</code> = amplitude at the target FFT bin (\u00b5V) - <code>noise_mean</code> = mean of the noise bins - <code>noise_std</code> = standard deviation of the noise bins</p> <p>Then:</p> <ul> <li>SNR = <code>A / noise_mean</code> (set to 0 when <code>noise_mean &lt;= 1e-12</code>)</li> <li>BCA = <code>A - noise_mean</code></li> <li>Z-score = <code>(A - noise_mean) / noise_std</code> (set to 0 when <code>noise_std &lt;= 1e-12</code>)</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Legacy_App/post_process.py</code>.)</p> <p>Full-spectrum SNR</p> <p>A separate full-spectrum SNR matrix is computed for all FFT bins using the same noise-bin logic and is exported as the <code>FullSNR</code> sheet.</p> <p>(Implementation verified in: <code>src/Tools/Stats/Legacy/full_snr.py</code> and <code>src/Main_App/Legacy_App/post_process.py</code>.)</p> <p>Background (not necessarily the toolbox implementation)</p> <p>FPVS studies often describe SNR based on a local noise window around each target frequency; always report the implementation actually used by the toolbox above.</p>"},{"location":"processing-pipeline/#7-roi-aggregation","title":"7) ROI aggregation","text":"<p>Important: The core processing/export step writes electrode-level metrics. ROI aggregation happens later (e.g., in the Stats tool) by reading the exported Excel files.</p> <p>Verified ROI aggregation behavior (Stats tool)</p> <ul> <li>ROI definitions are stored in settings as <code>roi_name \u2192 list of electrodes</code>,   with electrode names uppercased and trimmed for matching.</li> <li>For Summed BCA analyses, the toolbox:</li> <li>Reads the <code>BCA (uV)</code> sheet.</li> <li>Sums BCA across selected harmonics per electrode.</li> <li>Averages the summed values across electrodes in the ROI.</li> <li>Ignores ROI electrodes that are missing from the Excel file.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Legacy_App/settings_manager.py</code>, <code>src/Tools/Stats/PySide6/dv_policies.py</code>.)</p> <p>If you perform ROI aggregation outside the Stats tool (e.g., in a custom script), report the exact aggregation rule you used.</p>"},{"location":"processing-pipeline/#8-exports","title":"8) Exports","text":"<p>Output location</p> <ul> <li>The export root is the project\u2019s Excel results folder (default:   <code>1 - Excel Data Files</code> under the project\u2019s results directory).</li> <li>A subfolder is created per condition label (label is sanitized for filenames).</li> </ul> <p>(Implementation verified in: <code>src/Main_App/PySide6_App/Backend/project.py</code>, <code>src/Main_App/Legacy_App/post_process.py</code>.)</p> <p>Excel file names</p> <ul> <li>Single-file processing: <code>PID_&lt;Condition&gt;_Results.xlsx</code></li> <li><code>PID</code> is extracted from the raw filename using <code>P\\d+</code>, <code>Sub\\d+</code>, or <code>S\\d+</code>   patterns; otherwise a cleaned filename stem is used.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Legacy_App/post_process.py</code>.)</p> <p>Excel sheet names and contents</p> Sheet name Contents Columns <code>FFT Amplitude (uV)</code> Amplitude spectrum at target harmonics <code>Electrode</code>, <code>&lt;freq&gt;_Hz</code> <code>SNR</code> Signal-to-noise ratio at target harmonics <code>Electrode</code>, <code>&lt;freq&gt;_Hz</code> <code>Z Score</code> Z-scores at target harmonics <code>Electrode</code>, <code>&lt;freq&gt;_Hz</code> <code>BCA (uV)</code> Baseline-corrected amplitudes at target harmonics <code>Electrode</code>, <code>&lt;freq&gt;_Hz</code> <code>FullSNR</code> Full-spectrum SNR (interpolated) <code>Electrode</code>, <code>&lt;freq&gt;_Hz</code> <p>Target-harmonic columns are formatted as <code>\"{freq:.4f}_Hz\"</code>. The <code>FullSNR</code> sheet is interpolated from 0.5 Hz up to the configured <code>bca_upper_limit</code> in 0.01 Hz steps.</p> <p>(Implementation verified in: <code>src/Main_App/Legacy_App/post_process.py</code>.)</p>"},{"location":"processing-pipeline/#9-logging-reproducibility","title":"9) Logging / reproducibility","text":"<p>The pipeline writes structured log messages during preprocessing and processing. Key log entries you can cite for reproducibility include:</p> <ul> <li>Preprocessing fingerprint and filter snapshot (cutoffs, sampling rate).</li> <li>Number of channels rejected by kurtosis.</li> <li>Event source (stim vs. annotations) and number of events.</li> <li>Warnings for labels with zero events or zero epochs.</li> <li>Confirmation of Excel export completion.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/PySide6_App/Backend/preprocess.py</code>, <code>src/Main_App/Performance/process_runner.py</code>, <code>src/Main_App/Legacy_App/post_process.py</code>.)</p> <p>For manuscript archiving, keep: - The project settings/manifest (event map, preprocessing settings, ROI list). - The per-condition Excel outputs. - The processing log file or log window export.</p>"},{"location":"processing-pipeline/#what-to-report-in-your-manuscript-checklist","title":"What to report in your manuscript (checklist)","text":"<p>Fill in the values in brackets with your project\u2019s actual settings.</p> <ul> <li>Recording format and sampling rate: [e.g., BioSemi .bdf, 512 Hz]</li> <li>Stim/trigger channel: [e.g., Status]</li> <li>Initial reference: [e.g., EXG1/EXG2]</li> <li>Final reference: [average reference]</li> <li>Filter settings: [HPF = __ Hz, LPF = __ Hz]</li> <li>Downsampling: [target Hz or \u201cnot applied\u201d]</li> <li>Bad-channel handling: [kurtosis Z threshold __; interpolation on/off]</li> <li>Epoch window: [tmin = __ s, tmax = __ s; baseline = none]</li> <li>Event mapping: [list labels and integer codes]</li> <li>FFT method: [FFT of averaged epochs; amplitude = abs(FFT)/N*2]</li> <li>Frequency resolution: [N = samples per epoch \u2192 resolution = sfreq/N]</li> <li>Noise window for SNR/Z/BCA: [\u00b110 bins; exclude target \u00b11; drop max/min]</li> <li>Oddball harmonics analyzed: [oddball_freq, upper limit, resulting list]</li> <li>ROI definitions: [ROI name \u2192 electrode list; uppercased channel matching]</li> <li>Exported metrics and units: [SNR, Z, BCA (\u00b5V), FFT amplitude (\u00b5V)]</li> </ul>"},{"location":"processing-pipeline/#implementation-details-not-found-in-code","title":"Implementation details not found in code","text":"<p>If you need any of the following details for your manuscript, they are not verified in code and should be reported explicitly as user-configurable or unknown:</p> <ul> <li>Epoch rejection thresholds (amplitude/flat criteria)</li> <li>Searched in:<ul> <li><code>src/Main_App/Performance/process_runner.py</code> (keywords: <code>Epochs</code>, <code>reject</code>, <code>flat</code>)</li> <li><code>src/Main_App/Legacy_App/processing_utils.py</code> (keywords: <code>Epochs</code>, <code>reject</code>, <code>flat</code>)</li> </ul> </li> </ul> <p>If you know where these are configured in your local deployment, add them to this documentation and cite the exact configuration source.</p>"},{"location":"relevant-publications/","title":"Relevant Publications","text":"<p>This page lists key articles and books that informed the design of the FPVS Toolbox, including choices in paradigm design, preprocessing, and statistical analysis. It is not exhaustive, but it should give users a solid starting point to understand the methods behind the software.</p>"},{"location":"relevant-publications/#fpvs-ssvep-and-frequency-tagging-paradigms","title":"FPVS, SSVEP, and Frequency-Tagging Paradigms","text":"<ul> <li> <p>Vandenheever et. al, 2025 Exploring facial expression processing with fast periodic visual stimulation and diverse stimuli. Brain and Cognition. 2025; doi:10.1016/j.bandc.2025.106338.</p> </li> <li> <p>Vandenheever et. al, 2025. Preliminary evidence for anxiety linked neural sensitivity to emotional faces using fast periodic visual stimulation. International Journal of Psychophysiology. doi: 10.1016/j.ijpsycho.2025.113212.</p> </li> <li> <p>Rossion B, Torfs K, Jacques C, Liu-Shuang J. Fast periodic presentation of natural images reveals a robust face-selective electrophysiological response in the human brain. J Vis. 2015;15(1):15.1.18. Published 2015 Jan 16. doi:10.1167/15.1.18</p> </li> <li> <p>Rossion B, Retter TL, Liu-Shuang J. Understanding human individuation of unfamiliar faces with oddball fast periodic visual stimulation and electroencephalography. Eur J Neurosci. 2020;52(10):4283-4344. doi:10.1111/ejn.14865</p> </li> </ul> <p>These papers provide the main conceptual and analytical background for FPVS paradigms, oddball designs, and harmonic-based frequency-tagging analyses used in the Toolbox.</p>"},{"location":"relevant-publications/#eeg-erp-methods-and-preprocessing","title":"EEG / ERP Methods and Preprocessing","text":"<ul> <li> <p>Gil \u00c1vila, C., Bott, F.S., Tiemann, L. et al. DISCOVER-EEG: an open, fully automated EEG pipeline for biomarker discovery in clinical neuroscience. Sci Data 10, 613 (2023). https://doi.org/10.1038/s41597-023-02525-0</p> </li> <li> <p>Hern\u00e1ndez-Mustieles, M. A., Lima-Carmona, Y. E., Mendoza-Armenta, A. A., Hernandez-Machain, X., Garza-V\u00e9lez, D. A., Carrillo-M\u00e1rquez, A., Rodr\u00edguez-Alvarado, D. C., Lozoya-Santos, J. d. J., &amp; Ram\u00edrez-Moreno, M. A. (2024). An EEG Dataset of Subject Pairs during Collaboration and Competition Tasks in Face-to-Face and Online Modalities. Data, 9(4), 47. https://doi.org/10.3390/data9040047</p> </li> </ul> <p>These references give general foundations for EEG/ERP recording, artifact handling, filtering, referencing, and statistical analysis that inform the preprocessing pipeline.</p>"},{"location":"relevant-publications/#statistical-methods-and-linear-mixed-models","title":"Statistical Methods and Linear Mixed Models","text":"<ul> <li> <p>Boisgontier MP, Cheval B. The anova to mixed model transition. Neurosci Biobehav Rev. 2016;68:1004-1005. doi:10.1016/j.neubiorev.2016.05.034</p> </li> <li> <p>Matuschek, Hannes &amp; Kliegl, Reinhold &amp; Vasishth, Shravan &amp; Baayen, Harald &amp; Bates, Douglas. (2017). Balancing Type I Error and Power in Linear Mixed Models. Journal of Memory and Language. 94. 305\u2013315. 10.1016/j.jml.2017.01.001. </p> </li> <li> <p>Heise MJ, Mon SK, Bowman LC. Utility of linear mixed effects models for event-related potential research with infants and children. Dev Cogn Neurosci. 2022;54:101070. doi:10.1016/j.dcn.2022.101070</p> </li> </ul> <p>These works underpin the use of Benjamini\u2013Hochberg FDR correction and linear mixed-effects models for the statistical outputs generated by the FPVS Toolbox.</p>"},{"location":"relevant-publications/#how-to-cite-the-fpvs-toolbox","title":"How to Cite the FPVS Toolbox","text":"<p>If you use the FPVS Toolbox in a publication, please consider citing:</p> <p>Murphy Z., et al. FPVS Toolbox: Automated preprocessing and statistical analysis for fast periodic visual stimulation EEG experiments. [Manuscript in preparation / preprint details to be added here.]</p> <p>Update this section with the final reference once a preprint or paper is available.</p>"},{"location":"statistical-analysis/","title":"Statistical Analysis","text":"<p>This page summarizes the statistical methods used by the FPVS Toolbox Statistical Analysis module for end users. It focuses on the primary output measure (Summed BCA) and how to interpret results in the single-group and multi-group workflows.</p>"},{"location":"statistical-analysis/#how-the-methods-work-together-high-level","title":"How the methods work together (high-level)","text":"<ol> <li>Summed BCA DV is defined from the ROI-aggregated spectral outputs.</li> <li>Harmonics are selected (e.g., Rossion method) to decide which    oddball harmonics contribute to the DV.</li> <li>A subject \u00d7 condition \u00d7 ROI table of Summed BCA values is built.</li> <li>RM-ANOVA and/or a linear mixed-effects model summarize    condition, ROI, and interaction effects.</li> <li>Post-hoc paired t-tests (within each ROI) follow a significant    interaction to explain which condition pairs differ.</li> </ol> <p>Interpretation guide (single-group):</p> <ul> <li>Overall response present: Summed BCA values are consistently above   zero and/or the mixed-model intercept is positive. Note that RM-ANOVA   tests differences among conditions and ROIs; it does not directly test   DV vs 0 (Not found in code: an explicit one-sample test on Summed BCA   within the main RM-ANOVA pipeline). See \u201cNot found in code\u201d notes below.</li> <li>Condition main effect: responses differ across experimental   conditions (averaged across ROIs).</li> <li>ROI main effect: responses differ across ROIs (averaged across   conditions).</li> <li>Condition \u00d7 ROI interaction: the condition effect depends on which   ROI is considered.</li> </ul> <p>Cautions:</p> <ul> <li>Multiple comparisons: post-hoc tests are corrected for false   discovery rate; still interpret effect sizes and confidence intervals.</li> <li>Harmonic sets can differ by ROI (Rossion method). This can make ROI   differences partly reflect different harmonic selections.</li> <li>Assumptions: check normality and sphericity (RM-ANOVA) and residual   diagnostics (mixed model) as part of reporting.</li> </ul>"},{"location":"statistical-analysis/#summed-bca-dv-and-harmonic-selection","title":"Summed BCA DV and harmonic selection","text":"<p>The DV used for statistical analysis is the Summed baseline-corrected oddball amplitude (Summed BCA). It is computed per subject \u00d7 condition \u00d7 ROI by summing BCA across selected oddball harmonics and then averaging across ROI channels.</p> <ul> <li>Source data: The DV is computed from the \u201cBCA (uV)\u201d sheet in the   spectral/ROI output file; Z-score information used for harmonic   selection comes from the \u201cZ Score\u201d sheet.</li> <li>ROI aggregation: The ROI mean is computed after summing selected   harmonics for each channel within the ROI.</li> </ul> <p>For detailed harmonic selection rules (Rossion method), see: Rossion harmonic selection.</p>"},{"location":"statistical-analysis/#single-group-analyses","title":"Single-group analyses","text":""},{"location":"statistical-analysis/#repeated-measures-anova-rm-anova","title":"Repeated-measures ANOVA (RM-ANOVA)","text":"<ul> <li>Within-subject factors: Condition and ROI (plus their interaction).</li> <li>Implementation:</li> <li>Primary path: Pingouin <code>rm_anova</code> (detailed table when available,     including Greenhouse\u2013Geisser and Huynh\u2013Feldt corrections).</li> <li>Fallback: statsmodels <code>AnovaRM</code> if Pingouin is not available.</li> <li>Outputs: F statistic, numerator/denominator degrees of freedom,   p-values, and partial eta-squared effect sizes.</li> </ul> <p>Interpretation:</p> <ul> <li>F statistic: ratio of variance explained by the effect to residual   variance (larger F \u2192 stronger evidence for an effect).</li> <li>df1/df2: numerator/denominator degrees of freedom for the effect.</li> <li>GG/HF corrections: appear when Pingouin can compute sphericity   corrections.</li> </ul> <p>For more details, see: RM-ANOVA details.</p>"},{"location":"statistical-analysis/#post-hoc-tests-interaction-breakdown","title":"Post-hoc tests (interaction breakdown)","text":"<ul> <li>Paired t-tests between all condition pairs, run separately   within each ROI.</li> <li>Correction: Benjamini\u2013Hochberg FDR within each ROI (i.e., each   ROI\u2019s condition-pair family is corrected independently).</li> <li>Effect size: Cohen\u2019s dz for paired samples, based on the   subject-wise condition differences.</li> </ul> <p>For more details, see: Post-hoc tests.</p>"},{"location":"statistical-analysis/#linear-mixed-effects-model-single-group","title":"Linear mixed-effects model (single group)","text":"<ul> <li>Library: statsmodels <code>MixedLM</code>.</li> <li>Fixed effects: condition, ROI, and condition \u00d7 ROI interaction.</li> <li>Random effects: random intercept for subject.</li> <li>Coding: condition and ROI are sum-coded by default when present   (no explicit coding is set for other factors).</li> </ul> <p>For more details, see: Mixed model details.</p>"},{"location":"statistical-analysis/#multi-group-analyses","title":"Multi-group analyses","text":"<p>Multi-group mode compares two or more groups (e.g., clinical vs control).</p>"},{"location":"statistical-analysis/#between-group-anova-mixed-anova","title":"Between-group ANOVA (mixed ANOVA)","text":"<ul> <li>Factors: Group (between-subjects) \u00d7 Condition (within-subjects).</li> <li>DV: Summed BCA, typically collapsed across ROI for this test.</li> <li>Implementation: Pingouin <code>mixed_anova</code> is required; the fallback   does not support a between-group factor.</li> </ul>"},{"location":"statistical-analysis/#between-group-mixed-model","title":"Between-group mixed model","text":"<ul> <li>Fixed effects: group, condition, ROI, and all interactions.</li> <li>Random effects: random intercept for subject.</li> </ul>"},{"location":"statistical-analysis/#group-contrasts","title":"Group contrasts","text":"<ul> <li>Welch\u2019s t-tests (unequal variances) for each   condition \u00d7 ROI combination.</li> <li>Correction: Benjamini\u2013Hochberg FDR across all contrasts in the   output table.</li> <li>Effect size: Cohen\u2019s d for independent groups.</li> </ul>"},{"location":"statistical-analysis/#outliers-qc-flags-and-manual-exclusions","title":"Outliers, QC flags, and manual exclusions","text":"<p>The Stats tool can generate QC and DV flags and separate them from manual exclusions. See Outliers and QC for details.</p>"},{"location":"statistical-analysis/#output-files","title":"Output files","text":"<ul> <li>Results are written to the project\u2019s \u201c3 - Statistical Analysis   Results\u201d folder.</li> <li>Common exports include:</li> <li>RM-ANOVA tables.</li> <li>Mixed-model fixed-effects tables.</li> <li>Post-hoc tables with raw and FDR-adjusted p-values plus effect sizes.</li> <li>Rossion DV definition export (when using Rossion selection).</li> <li>Flagged and excluded participant reports (if QC/outlier checks are     enabled).</li> </ul>"},{"location":"statistical-analysis/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>An explicit one-sample test against zero as part of the RM-ANOVA   pipeline. (Searched in <code>src/Tools/Stats/PySide6/stats_workers.py</code>,   <code>src/Tools/Stats/Legacy/stats_analysis.py</code>, and   <code>src/Tools/Stats/Legacy/repeated_m_anova.py</code>.)</li> </ul>"},{"location":"tutorial/","title":"FPVS Toolbox: Getting Started","text":"<ol> <li>First, download the FPVS Toolbox installer from the latest release on github. Follow all instructions. You may have to manually bypass Windows Defender or other antivirus software.</li> </ol> <p>The rest of the FPVS Toolbox tutorial will be added soon. </p>"},{"location":"statistics/mixed-model/","title":"Linear mixed-effects model (Summed BCA)","text":"<p>The FPVS Toolbox provides a linear mixed-effects model (LMM) for Summed BCA, allowing you to model repeated measures within subjects while estimating condition/ROI effects.</p>"},{"location":"statistics/mixed-model/#implementation","title":"Implementation","text":"<ul> <li>Library: statsmodels <code>MixedLM</code>.</li> <li>Random effects: random intercept for each subject (default).</li> <li>Fixed effects (single group): condition, ROI, and their interaction.</li> <li>Fixed effects (multi-group): group, condition, ROI, and all   interactions.</li> </ul>"},{"location":"statistics/mixed-model/#coding-of-categorical-variables","title":"Coding of categorical variables","text":"<ul> <li>Condition and ROI are sum-coded by default when present.</li> <li>Group coding: Not found in code. The model does not explicitly set   group contrasts, so statsmodels\u2019 default coding likely applies.</li> </ul>"},{"location":"statistics/mixed-model/#how-to-interpret-coefficients","title":"How to interpret coefficients","text":"<ul> <li>Intercept: average Summed BCA across all conditions/ROIs (and   groups, if using sum coding). A positive intercept suggests an overall   response above zero.</li> <li>Condition terms: how each condition deviates from the overall mean   (under sum coding).</li> <li>ROI terms: how each ROI deviates from the overall mean.</li> <li>Interaction terms: whether condition effects differ by ROI (or by   group in multi-group mode).</li> </ul>"},{"location":"statistics/mixed-model/#relationship-to-rm-anova","title":"Relationship to RM-ANOVA","text":"<ul> <li>RM-ANOVA is the traditional repeated-measures approach (balanced   designs, sphericity corrections).</li> <li>Mixed model provides a flexible alternative that can handle some   missing data (after exclusions) and gives coefficient-level estimates.</li> </ul>"},{"location":"statistics/mixed-model/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>A user-facing toggle to enable random slopes or likelihood-ratio tests   (the helper supports these, but the Stats tool calls it with random   intercept only and no LRTs). (Searched in   <code>src/Tools/Stats/Legacy/mixed_effects_model.py</code> and   <code>src/Tools/Stats/PySide6/stats_workers.py</code>.)</li> </ul>"},{"location":"statistics/outliers-and-qc/","title":"Outliers, QC flags, and manual exclusions","text":"<p>The Statistical Analysis module separates flags (informational) from exclusions (participants actually removed from analysis). This lets you review QC warnings before deciding whether to exclude anyone.</p>"},{"location":"statistics/outliers-and-qc/#what-is-flagged-vs-excluded","title":"What is flagged vs. excluded","text":""},{"location":"statistics/outliers-and-qc/#qc-flags-informational","title":"QC flags (informational)","text":"<ul> <li>QC screening examines all conditions and ROIs in the project, even   if you later select a subset for analysis.</li> <li>QC uses robust thresholds on sum(|BCA|) and max(|BCA|) metrics   (across oddball harmonics) to flag unusually large responses.</li> <li>QC flags do not automatically remove participants. They appear in   the Flagged Participants report so you can review them.</li> </ul>"},{"location":"statistics/outliers-and-qc/#dv-hard-limit-flags-informational","title":"DV hard-limit flags (informational)","text":"<ul> <li>A hard DV limit (absolute value) flags participants whose Summed   BCA values exceed the limit.</li> <li>These are also flags only unless the value is non-finite.</li> </ul>"},{"location":"statistics/outliers-and-qc/#required-exclusions-automatic","title":"Required exclusions (automatic)","text":"<ul> <li>Participants with non-finite Summed BCA values are required   exclusions and are removed from analyses.</li> </ul>"},{"location":"statistics/outliers-and-qc/#manual-exclusions-user-controlled","title":"Manual exclusions (user-controlled)","text":"<ul> <li>You can manually select participants to exclude. This is the only   user-controlled exclusion step.</li> <li>Manual exclusions are applied before analyses run.</li> </ul>"},{"location":"statistics/outliers-and-qc/#where-to-find-the-reports","title":"Where to find the reports","text":"<p>Exports live in \u201c3 - Statistical Analysis Results\u201d and include:</p> <ul> <li>Flagged Participants.xlsx</li> <li>Flag Summary and Flag Details tabs for QC and DV flags.</li> <li>Excluded Participants.xlsx</li> <li>Records manual exclusions and required non-finite exclusions.</li> </ul>"},{"location":"statistics/outliers-and-qc/#interpretation-tips","title":"Interpretation tips","text":"<ul> <li>Use Flagged Participants.xlsx to document quality concerns and   justify any manual exclusions in your reporting.</li> <li>Because QC flags do not remove participants automatically, the   final sample size depends on manual exclusions plus required   non-finite exclusions.</li> </ul>"},{"location":"statistics/outliers-and-qc/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>A setting to automatically exclude QC-flagged participants. (Searched   in <code>src/Tools/Stats/PySide6/stats_workers.py</code> and   <code>src/Tools/Stats/PySide6/stats_outlier_exclusion.py</code>.)</li> </ul>"},{"location":"statistics/posthoc-tests/","title":"Post-hoc tests (interaction breakdown)","text":"<p>Post-hoc tests are run after an interaction is found in RM-ANOVA. They explain which condition pairs differ within each ROI.</p>"},{"location":"statistics/posthoc-tests/#what-is-tested","title":"What is tested","text":"<ul> <li>Within each ROI, the tool runs paired t-tests for every pair of   conditions.</li> <li>The analysis is within-subject, so each test uses subject-wise   differences between the two conditions.</li> </ul>"},{"location":"statistics/posthoc-tests/#multiple-comparison-correction","title":"Multiple-comparison correction","text":"<ul> <li>Correction method: Benjamini\u2013Hochberg FDR (<code>fdr_bh</code>).</li> <li>Correction family: applied within each ROI (all condition-pair   tests for that ROI are corrected together).</li> </ul>"},{"location":"statistics/posthoc-tests/#effect-sizes-and-outputs","title":"Effect sizes and outputs","text":"<p>Each pairwise result includes:</p> <ul> <li>t statistic and p-value (raw and FDR-adjusted).</li> <li>Cohen\u2019s dz (paired-samples effect size), computed as mean difference   divided by the standard deviation of paired differences.</li> <li>Mean difference (Condition A \u2212 Condition B) and 95% CI.</li> <li>Shapiro p-value for paired differences (informational only).</li> </ul> <p>Interpretation tips:</p> <ul> <li>Direction: a positive mean difference means Condition A &gt; Condition   B for Summed BCA.</li> <li>Effect size (dz): larger absolute values indicate stronger   condition differences within the ROI.</li> </ul>"},{"location":"statistics/posthoc-tests/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>A user-facing setting to change the post-hoc correction method from   Benjamini\u2013Hochberg FDR to another option. (Searched in   <code>src/Tools/Stats/Legacy/posthoc_tests.py</code> and   <code>src/Tools/Stats/PySide6/stats_workers.py</code>.)</li> </ul>"},{"location":"statistics/rm-anova/","title":"RM-ANOVA details (Summed BCA)","text":"<p>The FPVS Toolbox uses repeated-measures ANOVA (RM-ANOVA) to test within-subject effects of Condition, ROI, and their interaction on Summed BCA.</p>"},{"location":"statistics/rm-anova/#implementation","title":"Implementation","text":"<ul> <li>Primary library: Pingouin <code>rm_anova</code> (when installed).</li> <li>Fallback library: statsmodels <code>AnovaRM</code> (when Pingouin is not   available).</li> </ul> <p>The output is normalized into a consistent table that includes:</p> <ul> <li>Effect (Condition, ROI, Condition \u00d7 ROI)</li> <li>F Value (F statistic)</li> <li>Num DF / Den DF (degrees of freedom)</li> <li>Pr &gt; F (p-value)</li> <li>partial eta squared (effect size)</li> <li>Pr &gt; F (GG) and Pr &gt; F (HF) when Pingouin provides sphericity   corrections</li> </ul>"},{"location":"statistics/rm-anova/#how-to-read-the-table","title":"How to read the table","text":"<ul> <li>F statistic: ratio of explained variance to residual variance. A   larger F indicates stronger evidence for an effect.</li> <li>Num DF / Den DF: degrees of freedom for the effect and error.</li> <li>p-values: use the GG/HF corrected columns when available (they   adjust for sphericity violations).</li> <li>partial eta squared: effect size, computed from F and dfs when not   provided by the library.</li> </ul>"},{"location":"statistics/rm-anova/#notes-for-end-users","title":"Notes for end users","text":"<ul> <li>RM-ANOVA requires a balanced design (each subject must have all   required condition \u00d7 ROI combinations). If the data are unbalanced, the   analysis reports an error and lists missing combinations.</li> <li>RM-ANOVA focuses on differences among conditions and ROIs; it does   not directly test whether Summed BCA is different from zero.</li> </ul>"},{"location":"statistics/rm-anova/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>A user-facing setting that toggles sphericity correction methods   (Pingouin decides this internally). (Searched in   <code>src/Tools/Stats/Legacy/repeated_m_anova.py</code> and   <code>src/Tools/Stats/PySide6/stats_main_window.py</code>.)</li> </ul>"},{"location":"statistics/rossion-harmonic-selection/","title":"Rossion harmonic selection (Summed BCA)","text":"<p>This page explains the Rossion method used to define which oddball harmonics contribute to the Summed BCA DV. The method is ROI-specific and is based on group mean Z-scores computed from the Z-score sheet in your spectral output files.</p>"},{"location":"statistics/rossion-harmonic-selection/#what-the-method-produces","title":"What the method produces","text":"<p>For each ROI, the Rossion method produces a list of oddball harmonics (Hz). That list is then used to compute Summed BCA for every subject and every condition in that ROI.</p> <ul> <li>Per ROI: each ROI gets its own selected harmonic set.</li> <li>Per subject \u00d7 condition \u00d7 ROI: Summed BCA is the sum of BCA values   over those selected harmonics, averaged across channels in the ROI.</li> </ul>"},{"location":"statistics/rossion-harmonic-selection/#inputs-and-data-sources","title":"Inputs and data sources","text":"<p>The Rossion method uses the same per-subject, per-condition Excel output files that store ROI-aggregated spectral data.</p> <ul> <li>Z-score source: the \u201cZ Score\u201d sheet is used to compute group mean   Z-values for each ROI and harmonic.</li> <li>BCA source: the \u201cBCA (uV)\u201d sheet provides the BCA amplitudes to   be summed once harmonics are selected.</li> <li>Column format: frequency bins are read from columns that end in   <code>_Hz</code> (e.g., <code>1.2_Hz</code>).</li> </ul>"},{"location":"statistics/rossion-harmonic-selection/#step-1-build-the-candidate-harmonic-domain","title":"Step 1: Build the candidate harmonic domain","text":"<p>The tool builds the candidate harmonic list using the following steps:</p> <ol> <li>Read frequency columns from the Z-score sheet (columns ending in    <code>_Hz</code>).</li> <li>Exclude base-rate harmonics: any column that is an exact multiple    of the base frequency is removed (tolerance 1e-6).</li> <li>Select oddball harmonics: oddball harmonics are defined as    multiples of (base frequency / every_n), with the default    <code>every_n = 5</code> and tolerance 1e-3.</li> <li>Optional exclusion of harmonic 1: if \u201cExclude harmonic 1\u201d is    enabled, harmonic number 1 is removed from the list.</li> </ol> <p>Result: an ordered list of oddball harmonic frequencies (Hz) that are candidates for the Rossion selection rule.</p>"},{"location":"statistics/rossion-harmonic-selection/#step-2-compute-group-mean-z-per-roi-and-harmonic","title":"Step 2: Compute group mean Z per ROI and harmonic","text":"<p>For each subject, condition, ROI, and harmonic in the domain:</p> <ul> <li>The tool averages Z values across the ROI\u2019s channels (using the   channels that are present in the Z-score sheet).</li> <li>These ROI-mean Z values are pooled across all selected conditions and   all subjects, then averaged to yield a group mean Z for each   ROI \u00d7 harmonic.</li> </ul> <p>This produces a table with columns like:</p> <ul> <li><code>roi</code></li> <li><code>harmonic_hz</code></li> <li><code>mean_z</code> (group mean Z across selected conditions and subjects)</li> </ul>"},{"location":"statistics/rossion-harmonic-selection/#step-3-rossion-selection-rule-per-roi","title":"Step 3: Rossion selection rule (per ROI)","text":"<p>For each ROI, harmonics are scanned in ascending order:</p> <ul> <li>Threshold: a harmonic is significant if group mean Z exceeds the   current Z threshold (default 1.64). The threshold is set in the   Statistical Analysis settings.</li> <li>Arm after first significant: non-significant harmonics are ignored   until the first significant harmonic is found.</li> <li>Stop rule: after the first significant harmonic is found, the   algorithm stops after 2 consecutive non-significant harmonics.</li> </ul> <p>The selected harmonics are the significant harmonics before the stop rule triggers.</p>"},{"location":"statistics/rossion-harmonic-selection/#step-4-compute-summed-bca-the-dv","title":"Step 4: Compute Summed BCA (the DV)","text":"<p>For each subject \u00d7 condition \u00d7 ROI:</p> <ol> <li>Read BCA (uV) values at the selected harmonics for that ROI.</li> <li>Sum BCA across selected harmonics for each channel in the ROI.</li> <li>Average across ROI channels to yield the Summed BCA value.</li> </ol> <p>This produces the DV table used by RM-ANOVA, mixed models, and post-hoc comparisons.</p>"},{"location":"statistics/rossion-harmonic-selection/#fallback-behavior-when-no-harmonics-are-selected","title":"Fallback behavior when no harmonics are selected","text":"<p>If the Rossion method selects no harmonics for a given ROI, the behavior depends on the Empty list policy setting:</p> <ul> <li>Fallback to Fixed-K (default): use the Fixed-K selection (default   K = 5) instead of the empty list.</li> <li>Set DV = 0: keep the harmonic list empty and set Summed BCA to 0   for that ROI.</li> <li>Error: stop and report an error so you can adjust settings.</li> </ul> <p>The Fixed-K harmonics are also built from oddball harmonics (every_n = 5) and can optionally exclude harmonic 1 and base-rate harmonics.</p>"},{"location":"statistics/rossion-harmonic-selection/#outputs-you-can-review","title":"Outputs you can review","text":"<p>When you export results after running the Rossion method, the tool writes Summed BCA DV Definition.xlsx with:</p> <ul> <li>DV Definition (summary of the policy and thresholds),</li> <li>ROI Harmonics (selected harmonics per ROI, fallback use, stop   reason),</li> <li>Mean Z Table (group mean Z values used for selection).</li> </ul>"},{"location":"statistics/rossion-harmonic-selection/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>A user-facing description of how Z thresholds are labeled in the UI   beyond \u201cminimum group-mean Z value for a harmonic to count as   significant.\u201d (Searched in <code>src/Tools/Stats/PySide6/stats_main_window.py</code>   and <code>src/Tools/Stats/PySide6/dv_policies.py</code>.)</li> </ul>"}]}