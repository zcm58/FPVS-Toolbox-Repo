{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"FPVS Toolbox Documentation","text":"<p>The Fast Periodic Visual Stimulation (FPVS) Toolbox allows you to easily process EEG data from FPVS experiments and run statistical analyses on the resulting metrics. As of now, FPVS Toolbox only supports the BioSemi data format (.BDF) and FPVS experiments ran with PsychoPy. </p> <p>This documentation page is a work in progress and is not yet complete.</p> <p>Current app version: v1.6.0</p>"},{"location":"#quick-start","title":"Quick start","text":"<p>Install FPVS Toolbox    Download the latest installer from the GitHub Releases page and run it    on Windows. You may have to bypass Windows Defender if prompted. When you run FPVS Toolbox for the first time, you    will be asked to select a \"Project Root\". This is where all the different results from various projects you create    within FPVS Toolbox will live. I recommend that you avoid using cloud based folders like OneDrive - it sometimes    causes issues with Statistical Analysis. </p> <p>Create or open a project </p> <p>From the main window, choose \"Create New Project\". You will be prompted to title your project, select the number of experimental groups, and to name each group. Next, you will select the input folder for each group (wherever you have stored your .BDF files).</p> <p>You will need to input titles for each FPVS Condition in your experiment in the Main App GUI, as well as the     PsychoPy trigger code associated with that condition. </p> <ol> <li>Process EEG data </li> <li>Select an EEG file or batch folder.  </li> <li>Configure preprocessing (reference, downsampling, filters, artifact      handling) in the Settings panel.  </li> <li> <p>Click Start Processing to run the pipeline and generate metrics      and Excel outputs.</p> </li> <li> <p>Run statistical analysis</p> </li> <li> <p>Open Statistical Analysis in the sidebar to run single-group or    between-group analyses on the processed data.</p> </li> </ol>"},{"location":"#core-documentation","title":"Core documentation","text":"<ul> <li> <p>Processing Pipeline   Detailed description of how recordings are loaded, preprocessed, epoched,   and converted to frequency-domain metrics.</p> </li> <li> <p>Statistical Analysis   Overview of single-group and between-group analyses, models used, and   how to interpret the outputs.</p> </li> <li> <p>Relevant Publications   A brief overview of relevant publications on FPVS and the preprocessing pipeline used inside the FPVS Toolbox. </p> </li> <li> <p>Tutorials &amp; Walkthroughs   Step-by-step examples on how to use the FPVS Toolbox.</p> </li> </ul>"},{"location":"#project-links","title":"Project links","text":"<ul> <li>GitHub repository: <code>https://github.com/zcm58/FPVS-Toolbox-Repo&gt;</code></li> </ul>"},{"location":"processing-pipeline/","title":"Processing Pipeline","text":"<p>This page describes the single-file processing pipeline used by FPVS Toolbox. It is written for end users who need manuscript-ready Methods text and verified implementation details.</p>"},{"location":"processing-pipeline/#manuscript-ready-summary-copypaste","title":"Manuscript-ready summary (copy/paste)","text":"<p>The FPVS Toolbox processes EEG recordings stored as BioSemi .bdf files using MNE-Python for loading, channel typing, and preprocessing. For each recording, the toolbox loads data with disk-backed memory mapping when available, assigns channel types (including a configured stimulus/trigger channel), and applies a standard 10\u201310 montage. Preprocessing follows a fixed sequence: initial re-reference to a user-specified pair of electrodes (default EXG1 and EXG2),  removal of those EXG channels, optional channel-count limiting, optional downsampling,  zero-phase FIR bandpass filtering, kurtosis-based bad-channel detection with interpolation,  and a final average re-reference. Events are extracted from the stim channel then epochs are created  for each user-defined condition label using a configured time window without baseline  correction. The time-domain data are averaged across epochs per condition,  transformed with an FFT, and  frequency-domain metrics are computed at the target oddball  harmonics (SNR, baseline-corrected amplitude, and Z-score). Results are exported to  per-condition Excel files (electrode-level metrics and a full-spectrum SNR sheet), which  serve as inputs for ROI aggregation and statistical analyses in the Stats tool.</p> <p>Parameter placeholders: Use the processing log and project settings/manifest (exported from the UI) to fill in your actual values for reference channels, filters, epoch window, and oddball frequency settings.</p>"},{"location":"processing-pipeline/#single-file-pipeline-verified-order","title":"Single-file pipeline (verified order)","text":"<p>The steps below reflect the linear processing order for one recording file as implemented in the current codebase. \u201cImplementation verified in:\u201d notes point you to the exact modules that define each step.</p>"},{"location":"processing-pipeline/#1-data-import-file-loading","title":"1) Data import / file loading","text":"<p>What happens</p> <ul> <li>Supported input types: <code>.bdf</code> (BioSemi). Other formats   are rejected. (Implementation verified in: <code>src/Main_App/PySide6_App/Backend/loader.py</code>.)</li> <li>Disk-backed memory mapping: the loader requests a disk-backed <code>preload</code> path   for <code>.bdf</code> and (when supported) <code>.set</code> files, then materializes the memmap with   <code>raw.load_data()</code> to keep RAM use bounded. (Implementation verified in:   <code>src/Main_App/PySide6_App/Backend/loader.py</code>.)</li> <li>Channel typing policy:</li> <li>The stimulus/trigger channel is explicitly typed as <code>stim</code>.</li> <li>The reference pair (e.g., EXG1/EXG2) is preserved as <code>eeg</code> so it can be     used for re-referencing.</li> <li>Other EXG channels (EXG1\u2013EXG8 not in the reference pair) are demoted to     <code>misc</code>.   (Implementation verified in: <code>src/Main_App/PySide6_App/Backend/loader.py</code>.)</li> <li>Montage: a standard 10\u201320 montage (<code>standard_1020</code>) is applied with   <code>on_missing=\"warn\"</code> and case-insensitive matching. (Implementation verified in:   <code>src/Main_App/PySide6_App/Backend/loader.py</code>.)</li> </ul> <p>Key parameters</p> Parameter Default Source Notes <code>stim_channel</code> <code>Status</code> Project settings / global settings Used for event detection and typed as <code>stim</code>. <code>ref_channel1</code>, <code>ref_channel2</code> <code>EXG1</code>, <code>EXG2</code> Project settings / global settings Kept as <code>eeg</code> during loading. <p>(Defaults verified in: <code>src/Main_App/PySide6_App/Backend/loader.py</code>, <code>src/Main_App/PySide6_App/Backend/preprocessing_settings.py</code>.)</p>"},{"location":"processing-pipeline/#2-preprocessing-fixed-order","title":"2) Preprocessing (fixed order)","text":"<p>Preprocessing is applied in a fixed sequence. Each operation is optional only if its parameter is unset/disabled.</p> <p>Fixed order (implementation verified in <code>src/Main_App/PySide6_App/Backend/preprocess.py</code>):</p> <ol> <li>Initial re-reference to the user-selected EXG pair (if both channels are    present). The reference pair is applied using <code>raw.set_eeg_reference(...)</code>.</li> <li>Drop reference channels: the two reference channels are removed from the    data after re-referencing.</li> <li>Optional channel limit: if <code>max_idx_keep</code> is set and smaller than the    current channel count, only the first N channels are retained plus the    stim channel (if present).</li> <li>Optional downsampling: if <code>downsample_rate</code> is set and lower than the    current sampling rate, the data are resampled with a Hann window.</li> <li>FIR bandpass filter (zero-phase, forward/backward):</li> <li>Method: <code>fir</code> with <code>firwin</code> design, <code>hamming</code> window, <code>phase=\"zero-double\"</code>.</li> <li>Transition bandwidths: 0.1 Hz (low and high).</li> <li>Fixed filter length: 8449 points.</li> <li>Kurtosis-based bad-channel detection &amp; interpolation:</li> <li>Kurtosis (Fisher, <code>bias=False</code>) is computed per EEG channel.</li> <li>A trimmed mean/std is computed by removing 10% of the highest and lowest      kurtosis values.</li> <li>Channels with <code>|z| &gt; rejection_z</code> are marked bad.</li> <li>If a montage is present, bad channels are interpolated      (<code>reset_bads=True</code>, <code>mode=\"accurate\"</code>).</li> <li>Final average reference: average reference is applied via projection and    immediately applied (<code>apply_proj</code>).</li> </ol> <p>Key parameters (defaults)</p> Parameter Default Purpose <code>high_pass</code> 0.1 Hz High-pass cutoff (HPF) <code>low_pass</code> 50.0 Hz Low-pass cutoff (LPF) <code>downsample</code> / <code>downsample_rate</code> 256 Hz Target sampling rate <code>rejection_z</code> / <code>reject_thresh</code> 5.0 Kurtosis Z threshold <code>max_idx_keep</code> 64 Max channel index to keep <code>ref_channel1</code>, <code>ref_channel2</code> EXG1 / EXG2 Initial reference pair <p>(Defaults verified in: <code>src/Main_App/PySide6_App/Backend/preprocessing_settings.py</code>.)</p> <p>Logged/audited items</p> <ul> <li>A preprocessing fingerprint string (HP/LP/downsample/reject/ref/stim).</li> <li>Filter snapshot (computed cutoffs and sampling rate).</li> <li>Number of bad channels rejected by kurtosis.</li> <li>Final sampling rate and channel count.</li> </ul> <p>(Logging verified in: <code>src/Main_App/PySide6_App/Backend/preprocess.py</code>.)</p>"},{"location":"processing-pipeline/#3-event-detection-and-condition-mapping","title":"3) Event detection and condition mapping","text":"<p>Event detection (single-file pipeline)</p> <ul> <li>The toolbox attempts to read events from the configured stim channel using   <code>mne.find_events(...)</code>.</li> <li>If stim-based extraction fails, it falls back to   <code>mne.events_from_annotations(...)</code>.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Performance/process_runner.py</code>.)</p> <p>Condition mapping</p> <ul> <li>Your Event Map supplies <code>label \u2192 integer code</code> pairs.</li> <li>For each label, events are included only if that integer code is present in   the extracted events.</li> <li>If a label has zero matching events, the pipeline logs a warning and skips   that label for the file.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Performance/process_runner.py</code>.)</p>"},{"location":"processing-pipeline/#4-epoching","title":"4) Epoching","text":"<ul> <li>Epochs are created per label with:</li> <li><code>tmin = epoch_start</code> and <code>tmax = epoch_end</code> (seconds)</li> <li><code>baseline = None</code> (no baseline correction at epoch stage)</li> <li><code>preload = False</code></li> <li><code>decim = 1</code></li> <li>After creation, <code>epochs.drop_bad()</code> is called.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Performance/process_runner.py</code>.)</p> <p>Not found in code; user-configurable / unknown</p> <ul> <li>Epoch rejection thresholds (e.g., voltage limits): no explicit <code>reject</code>   or <code>flat</code> criteria are passed to <code>mne.Epochs</code>. Search locations:</li> <li><code>src/Main_App/Performance/process_runner.py</code> (keywords: <code>Epochs</code>, <code>reject</code>, <code>flat</code>)</li> <li><code>src/Main_App/Legacy_App/processing_utils.py</code> (keywords: <code>Epochs</code>, <code>reject</code>, <code>flat</code>)</li> </ul>"},{"location":"processing-pipeline/#5-frequency-domain-analysis-fft","title":"5) Frequency-domain analysis (FFT)","text":"<ul> <li>For each condition, epochs are averaged in the time domain and the FFT is   computed on the averaged signal (not per-epoch).</li> <li>FFT uses <code>np.fft.fft</code> with no explicit windowing, detrending, or zero-padding.</li> <li>The amplitude spectrum is computed as:   <code>abs(FFT) / N * 2</code> for bins from 0 to Nyquist.</li> <li>Frequency bins are linearly spaced from 0 to <code>sfreq / 2</code>.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Legacy_App/post_process.py</code>.)</p>"},{"location":"processing-pipeline/#6-metric-computation-snr-bca-z-score","title":"6) Metric computation (SNR, BCA, Z-score)","text":"<p>Target frequencies</p> <ul> <li>The toolbox computes metrics at oddball harmonics defined by   <code>TARGET_FREQUENCIES</code>.</li> <li>These are calculated as: <code>oddball_freq \u00d7 1..K</code>, where   <code>K = round(bca_upper_limit / oddball_freq)</code>.</li> <li><code>oddball_freq</code> and <code>bca_upper_limit</code> come from project settings.</li> </ul> <p>(Implementation verified in: <code>src/config.py</code>.)</p> <p>Noise window and baseline definition (used by SNR, BCA, Z)</p> <p>For each target frequency, the toolbox finds the nearest FFT bin and defines noise bins as follows:</p> <ul> <li>Window: \u00b110 bins around the target bin.</li> <li>Exclusions: target bin and its immediate neighbors (\u22121 and +1) are excluded.</li> <li>Minimum bins: if fewer than 4 candidate bins remain, noise mean/std are set   to 0.0.</li> <li>Trimming: one maximum and one minimum value are removed before computing the   mean and standard deviation.</li> <li>Standard deviation uses population variance (<code>ddof=0</code>).</li> </ul> <p>(Implementation verified in: <code>src/Tools/Stats/Legacy/noise_utils.py</code> and <code>src/Main_App/Legacy_App/post_process.py</code>.)</p> <p>Formulas (applied per channel \u00d7 harmonic)</p> <p>Let: - <code>A</code> = amplitude at the target FFT bin (\u00b5V) - <code>noise_mean</code> = mean of the noise bins - <code>noise_std</code> = standard deviation of the noise bins</p> <p>Then:</p> <ul> <li>SNR = <code>A / noise_mean</code> (set to 0 when <code>noise_mean &lt;= 1e-12</code>)</li> <li>BCA = <code>A - noise_mean</code></li> <li>Z-score = <code>(A - noise_mean) / noise_std</code> (set to 0 when <code>noise_std &lt;= 1e-12</code>)</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Legacy_App/post_process.py</code>.)</p> <p>Full-spectrum SNR</p> <p>A separate full-spectrum SNR matrix is computed for all FFT bins using the same noise-bin logic and is exported as the <code>FullSNR</code> sheet.</p> <p>(Implementation verified in: <code>src/Tools/Stats/Legacy/full_snr.py</code> and <code>src/Main_App/Legacy_App/post_process.py</code>.)</p> <p>Background (not necessarily the toolbox implementation)</p> <p>FPVS studies often describe SNR based on a local noise window around each target frequency; always report the implementation actually used by the toolbox above.</p>"},{"location":"processing-pipeline/#7-roi-aggregation","title":"7) ROI aggregation","text":"<p>Important: The core processing/export step writes electrode-level metrics. ROI aggregation happens later (e.g., in the Stats tool) by reading the exported Excel files.</p> <p>Verified ROI aggregation behavior (Stats tool)</p> <ul> <li>ROI definitions are stored in settings as <code>roi_name \u2192 list of electrodes</code>,   with electrode names uppercased and trimmed for matching.</li> <li>For Summed BCA analyses, the toolbox:</li> <li>Reads the <code>BCA (uV)</code> sheet.</li> <li>Sums BCA across selected harmonics per electrode.</li> <li>Averages the summed values across electrodes in the ROI.</li> <li>Ignores ROI electrodes that are missing from the Excel file.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Legacy_App/settings_manager.py</code>, <code>src/Tools/Stats/PySide6/dv_policies.py</code>.)</p> <p>If you perform ROI aggregation outside the Stats tool (e.g., in a custom script), report the exact aggregation rule you used.</p>"},{"location":"processing-pipeline/#8-exports","title":"8) Exports","text":"<p>Output location</p> <ul> <li>The export root is the project\u2019s Excel results folder (default:   <code>1 - Excel Data Files</code> under the project\u2019s results directory).</li> <li>A subfolder is created per condition label (label is sanitized for filenames).</li> </ul> <p>(Implementation verified in: <code>src/Main_App/PySide6_App/Backend/project.py</code>, <code>src/Main_App/Legacy_App/post_process.py</code>.)</p> <p>Excel file names</p> <ul> <li>Single-file processing: <code>PID_&lt;Condition&gt;_Results.xlsx</code></li> <li><code>PID</code> is extracted from the raw filename using <code>P\\d+</code>, <code>Sub\\d+</code>, or <code>S\\d+</code>   patterns; otherwise a cleaned filename stem is used.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/Legacy_App/post_process.py</code>.)</p> <p>Excel sheet names and contents</p> Sheet name Contents Columns <code>FFT Amplitude (uV)</code> Amplitude spectrum at target harmonics <code>Electrode</code>, <code>&lt;freq&gt;_Hz</code> <code>SNR</code> Signal-to-noise ratio at target harmonics <code>Electrode</code>, <code>&lt;freq&gt;_Hz</code> <code>Z Score</code> Z-scores at target harmonics <code>Electrode</code>, <code>&lt;freq&gt;_Hz</code> <code>BCA (uV)</code> Baseline-corrected amplitudes at target harmonics <code>Electrode</code>, <code>&lt;freq&gt;_Hz</code> <code>FullSNR</code> Full-spectrum SNR (interpolated) <code>Electrode</code>, <code>&lt;freq&gt;_Hz</code> <p>Target-harmonic columns are formatted as <code>\"{freq:.4f}_Hz\"</code>. The <code>FullSNR</code> sheet is interpolated from 0.5 Hz up to the configured <code>bca_upper_limit</code> in 0.01 Hz steps.</p> <p>(Implementation verified in: <code>src/Main_App/Legacy_App/post_process.py</code>.)</p>"},{"location":"processing-pipeline/#9-logging-reproducibility","title":"9) Logging / reproducibility","text":"<p>The pipeline writes structured log messages during preprocessing and processing. Key log entries you can cite for reproducibility include:</p> <ul> <li>Preprocessing fingerprint and filter snapshot (cutoffs, sampling rate).</li> <li>Number of channels rejected by kurtosis.</li> <li>Event source (stim vs. annotations) and number of events.</li> <li>Warnings for labels with zero events or zero epochs.</li> <li>Confirmation of Excel export completion.</li> </ul> <p>(Implementation verified in: <code>src/Main_App/PySide6_App/Backend/preprocess.py</code>, <code>src/Main_App/Performance/process_runner.py</code>, <code>src/Main_App/Legacy_App/post_process.py</code>.)</p> <p>For manuscript archiving, keep: - The project settings/manifest (event map, preprocessing settings, ROI list). - The per-condition Excel outputs. - The processing log file or log window export.</p>"},{"location":"processing-pipeline/#what-to-report-in-your-manuscript-checklist","title":"What to report in your manuscript (checklist)","text":"<p>Fill in the values in brackets with your project\u2019s actual settings.</p> <ul> <li>Recording format and sampling rate: [e.g., BioSemi .bdf, 512 Hz]</li> <li>Stim/trigger channel: [e.g., Status]</li> <li>Initial reference: [e.g., EXG1/EXG2]</li> <li>Final reference: [average reference]</li> <li>Filter settings: [HPF = __ Hz, LPF = __ Hz]</li> <li>Downsampling: [target Hz or \u201cnot applied\u201d]</li> <li>Bad-channel handling: [kurtosis Z threshold __; interpolation on/off]</li> <li>Epoch window: [tmin = __ s, tmax = __ s; baseline = none]</li> <li>Event mapping: [list labels and integer codes]</li> <li>FFT method: [FFT of averaged epochs; amplitude = abs(FFT)/N*2]</li> <li>Frequency resolution: [N = samples per epoch \u2192 resolution = sfreq/N]</li> <li>Noise window for SNR/Z/BCA: [\u00b110 bins; exclude target \u00b11; drop max/min]</li> <li>Oddball harmonics analyzed: [oddball_freq, upper limit, resulting list]</li> <li>ROI definitions: [ROI name \u2192 electrode list; uppercased channel matching]</li> <li>Exported metrics and units: [SNR, Z, BCA (\u00b5V), FFT amplitude (\u00b5V)]</li> </ul>"},{"location":"processing-pipeline/#implementation-details-not-found-in-code","title":"Implementation details not found in code","text":"<p>If you need any of the following details for your manuscript, they are not verified in code and should be reported explicitly as user-configurable or unknown:</p> <ul> <li>Epoch rejection thresholds (amplitude/flat criteria)</li> <li>Searched in:<ul> <li><code>src/Main_App/Performance/process_runner.py</code> (keywords: <code>Epochs</code>, <code>reject</code>, <code>flat</code>)</li> <li><code>src/Main_App/Legacy_App/processing_utils.py</code> (keywords: <code>Epochs</code>, <code>reject</code>, <code>flat</code>)</li> </ul> </li> </ul> <p>If you know where these are configured in your local deployment, add them to this documentation and cite the exact configuration source.</p>"},{"location":"relevant-publications/","title":"Relevant Publications","text":"<p>This page lists key articles and books that informed the design of the FPVS Toolbox, including choices in paradigm design, preprocessing, and statistical analysis. It is not exhaustive, but it should give users a solid starting point to understand the methods behind the software.</p>"},{"location":"relevant-publications/#fpvs-ssvep-and-frequency-tagging-paradigms","title":"FPVS, SSVEP, and Frequency-Tagging Paradigms","text":"<ul> <li> <p>Vandenheever et. al, 2025 Exploring facial expression processing with fast periodic visual stimulation and diverse stimuli. Brain and Cognition. 2025; doi:10.1016/j.bandc.2025.106338.</p> </li> <li> <p>Vandenheever et. al, 2025. Preliminary evidence for anxiety linked neural sensitivity to emotional faces using fast periodic visual stimulation. International Journal of Psychophysiology. doi: 10.1016/j.ijpsycho.2025.113212.</p> </li> <li> <p>Rossion B, Torfs K, Jacques C, Liu-Shuang J. Fast periodic presentation of natural images reveals a robust face-selective electrophysiological response in the human brain. J Vis. 2015;15(1):15.1.18. Published 2015 Jan 16. doi:10.1167/15.1.18</p> </li> <li> <p>Rossion B, Retter TL, Liu-Shuang J. Understanding human individuation of unfamiliar faces with oddball fast periodic visual stimulation and electroencephalography. Eur J Neurosci. 2020;52(10):4283-4344. doi:10.1111/ejn.14865</p> </li> <li> <p>David, J., Quenon, L., Hanseeuw, B., Ivanoiu, A., Volfart, A., Koessler, L., &amp; Rossion, B. (2025). An objective and sensitive electrophysiological marker of word semantic categorization impairment in Alzheimer's disease. Clinical Neurophysiology, 170, 98\u2013109. https://doi.org/10.1016/j.clinph.2024.12.018</p> </li> </ul> <p>These papers provide the main conceptual and analytical background for FPVS paradigms, oddball designs, and harmonic-based frequency-tagging analyses used in the Toolbox.</p>"},{"location":"relevant-publications/#eeg-erp-methods-and-preprocessing","title":"EEG / ERP Methods and Preprocessing","text":"<ul> <li> <p>Gil \u00c1vila, C., Bott, F.S., Tiemann, L. et al. DISCOVER-EEG: an open, fully automated EEG pipeline for biomarker discovery in clinical neuroscience. Sci Data 10, 613 (2023). https://doi.org/10.1038/s41597-023-02525-0</p> </li> <li> <p>Hern\u00e1ndez-Mustieles, M. A., Lima-Carmona, Y. E., Mendoza-Armenta, A. A., Hernandez-Machain, X., Garza-V\u00e9lez, D. A., Carrillo-M\u00e1rquez, A., Rodr\u00edguez-Alvarado, D. C., Lozoya-Santos, J. d. J., &amp; Ram\u00edrez-Moreno, M. A. (2024). An EEG Dataset of Subject Pairs during Collaboration and Competition Tasks in Face-to-Face and Online Modalities. Data, 9(4), 47. https://doi.org/10.3390/data9040047</p> </li> </ul> <p>These references give general foundations for EEG/ERP recording, artifact handling, filtering, referencing, and statistical analysis that inform the preprocessing pipeline.</p>"},{"location":"relevant-publications/#statistical-methods-and-linear-mixed-models","title":"Statistical Methods and Linear Mixed Models","text":"<ul> <li> <p>Boisgontier MP, Cheval B. The anova to mixed model transition. Neurosci Biobehav Rev. 2016;68:1004-1005. doi:10.1016/j.neubiorev.2016.05.034</p> </li> <li> <p>Matuschek, Hannes &amp; Kliegl, Reinhold &amp; Vasishth, Shravan &amp; Baayen, Harald &amp; Bates, Douglas. (2017). Balancing Type I Error and Power in Linear Mixed Models. Journal of Memory and Language. 94. 305\u2013315. 10.1016/j.jml.2017.01.001. </p> </li> <li> <p>Heise MJ, Mon SK, Bowman LC. Utility of linear mixed effects models for event-related potential research with infants and children. Dev Cogn Neurosci. 2022;54:101070. doi:10.1016/j.dcn.2022.101070</p> </li> </ul> <p>These works underpin the use of Benjamini\u2013Hochberg FDR correction and linear mixed-effects models for the statistical outputs generated by the FPVS Toolbox.</p>"},{"location":"relevant-publications/#how-to-cite-the-fpvs-toolbox","title":"How to Cite the FPVS Toolbox","text":"<p>If you use the FPVS Toolbox in a publication, please consider citing:</p> <p>Murphy Z., et al. FPVS Toolbox: Automated preprocessing and statistical analysis for fast periodic visual stimulation EEG experiments. [Manuscript in preparation / preprint details to be added here.]</p> <p>Update this section with the final reference once a preprint or paper is available.</p>"},{"location":"statistical-analysis/","title":"Statistical Analysis","text":"<p>This page summarizes the statistical methods used by the FPVS Toolbox Statistical Analysis module for end users. It focuses on the primary output measure (Summed BCA) and how to interpret results in the single-group and multi-group workflows.</p>"},{"location":"statistical-analysis/#how-the-methods-work-together-high-level","title":"How the methods work together (high-level)","text":"<ol> <li>Summed BCA DV is defined from the ROI-aggregated spectral outputs.</li> <li>Harmonics are selected (e.g., Rossion method) to decide which    oddball harmonics contribute to the DV.</li> <li>A subject \u00d7 condition \u00d7 ROI table of Summed BCA values is built.</li> <li>RM-ANOVA and/or a linear mixed-effects model summarize    condition, ROI, and interaction effects.</li> <li>Post-hoc paired t-tests (within each ROI) follow a significant    interaction to explain which condition pairs differ.</li> </ol> <p>Interpretation guide (single-group):</p> <ul> <li>Overall response present: Summed BCA values are consistently above   zero and/or the mixed-model intercept is positive. Note that RM-ANOVA   tests differences among conditions and ROIs; it does not directly test   DV vs 0 (Not found in code: an explicit one-sample test on Summed BCA   within the main RM-ANOVA pipeline). See \u201cNot found in code\u201d notes below.</li> <li>Condition main effect: responses differ across experimental   conditions (averaged across ROIs).</li> <li>ROI main effect: responses differ across ROIs (averaged across   conditions).</li> <li>Condition \u00d7 ROI interaction: the condition effect depends on which   ROI is considered.</li> </ul> <p>Cautions:</p> <ul> <li>Multiple comparisons: post-hoc tests are corrected for false   discovery rate; still interpret effect sizes and confidence intervals.</li> <li>Harmonic sets can differ by ROI (Rossion method). This can make ROI   differences partly reflect different harmonic selections.</li> <li>Assumptions: check normality and sphericity (RM-ANOVA) and residual   diagnostics (mixed model) as part of reporting.</li> </ul>"},{"location":"statistical-analysis/#summed-bca-dv-and-harmonic-selection","title":"Summed BCA DV and harmonic selection","text":"<p>The DV used for statistical analysis is the Summed baseline-corrected oddball amplitude (Summed BCA). It is computed per subject \u00d7 condition \u00d7 ROI by summing BCA across selected oddball harmonics and then averaging across ROI channels.</p> <ul> <li>Source data: The DV is computed from the \u201cBCA (uV)\u201d sheet in the   spectral/ROI output file; Z-score information used for harmonic   selection comes from the \u201cZ Score\u201d sheet.</li> <li>ROI aggregation: The ROI mean is computed after summing selected   harmonics for each channel within the ROI.</li> </ul> <p>For detailed harmonic selection rules (Rossion method), see: Rossion harmonic selection.</p>"},{"location":"statistical-analysis/#single-group-analyses","title":"Single-group analyses","text":""},{"location":"statistical-analysis/#repeated-measures-anova-rm-anova","title":"Repeated-measures ANOVA (RM-ANOVA)","text":"<ul> <li>Within-subject factors: Condition and ROI (plus their interaction).</li> <li>Implementation:</li> <li>Primary path: Pingouin <code>rm_anova</code> (detailed table when available,     including Greenhouse\u2013Geisser and Huynh\u2013Feldt corrections).</li> <li>Fallback: statsmodels <code>AnovaRM</code> if Pingouin is not available.</li> <li>Outputs: F statistic, numerator/denominator degrees of freedom,   p-values, and partial eta-squared effect sizes.</li> </ul> <p>Interpretation:</p> <ul> <li>F statistic: ratio of variance explained by the effect to residual   variance (larger F \u2192 stronger evidence for an effect).</li> <li>df1/df2: numerator/denominator degrees of freedom for the effect.</li> <li>GG/HF corrections: appear when Pingouin can compute sphericity   corrections.</li> </ul> <p>For more details, see: RM-ANOVA details.</p>"},{"location":"statistical-analysis/#post-hoc-tests-interaction-breakdown","title":"Post-hoc tests (interaction breakdown)","text":"<ul> <li>Paired t-tests between all condition pairs, run separately   within each ROI.</li> <li>Correction: Benjamini\u2013Hochberg FDR within each ROI (i.e., each   ROI\u2019s condition-pair family is corrected independently).</li> <li>Effect size: Cohen\u2019s dz for paired samples, based on the   subject-wise condition differences.</li> </ul> <p>For more details, see: Post-hoc tests.</p>"},{"location":"statistical-analysis/#linear-mixed-effects-model-single-group","title":"Linear mixed-effects model (single group)","text":"<ul> <li>Library: statsmodels <code>MixedLM</code>.</li> <li>Fixed effects: condition, ROI, and condition \u00d7 ROI interaction.</li> <li>Random effects: random intercept for subject.</li> <li>Coding: condition and ROI are sum-coded by default when present   (no explicit coding is set for other factors).</li> </ul> <p>For more details, see: Mixed model details.</p>"},{"location":"statistical-analysis/#multi-group-analyses","title":"Multi-group analyses","text":"<p>Multi-group mode compares two or more groups (e.g., clinical vs control).</p>"},{"location":"statistical-analysis/#between-group-anova-mixed-anova","title":"Between-group ANOVA (mixed ANOVA)","text":"<ul> <li>Factors: Group (between-subjects) \u00d7 Condition (within-subjects).</li> <li>DV: Summed BCA, typically collapsed across ROI for this test.</li> <li>Implementation: Pingouin <code>mixed_anova</code> is required; the fallback   does not support a between-group factor.</li> </ul>"},{"location":"statistical-analysis/#between-group-mixed-model","title":"Between-group mixed model","text":"<ul> <li>Fixed effects: group, condition, ROI, and all interactions.</li> <li>Random effects: random intercept for subject.</li> </ul>"},{"location":"statistical-analysis/#group-contrasts","title":"Group contrasts","text":"<ul> <li>Welch\u2019s t-tests (unequal variances) for each   condition \u00d7 ROI combination.</li> <li>Correction: Benjamini\u2013Hochberg FDR across all contrasts in the   output table.</li> <li>Effect size: Cohen\u2019s d for independent groups.</li> </ul>"},{"location":"statistical-analysis/#outliers-qc-flags-and-manual-exclusions","title":"Outliers, QC flags, and manual exclusions","text":"<p>The Stats tool can generate QC and DV flags and separate them from manual exclusions. See Outliers and QC for details.</p>"},{"location":"statistical-analysis/#output-files","title":"Output files","text":"<ul> <li>Results are written to the project\u2019s \u201c3 - Statistical Analysis   Results\u201d folder.</li> <li>Common exports include:</li> <li>RM-ANOVA tables.</li> <li>Mixed-model fixed-effects tables.</li> <li>Post-hoc tables with raw and FDR-adjusted p-values plus effect sizes.</li> <li>Rossion DV definition export (when using Rossion selection).</li> <li>Flagged and excluded participant reports (if QC/outlier checks are     enabled).</li> </ul>"},{"location":"statistical-analysis/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following details were not found in code while preparing this page:</p> <ul> <li>An explicit one-sample test against zero as part of the RM-ANOVA   pipeline. (Searched in <code>src/Tools/Stats/PySide6/stats_workers.py</code>,   <code>src/Tools/Stats/Legacy/stats_analysis.py</code>, and   <code>src/Tools/Stats/Legacy/repeated_m_anova.py</code>.)</li> </ul>"},{"location":"tutorial/","title":"FPVS Toolbox: Getting Started","text":"<ol> <li>First, download the FPVS Toolbox installer from the latest release on github. Follow all instructions. You may have to manually bypass Windows Defender or other antivirus software.</li> </ol> <p>The rest of the FPVS Toolbox tutorial will be added soon. </p>"},{"location":"statistics/mixed-model/","title":"Linear mixed-effects model (Summed BCA)","text":""},{"location":"statistics/mixed-model/#plain-language-overview","title":"Plain-language overview","text":"<p>A linear mixed-effects model (often shortened to \u201cmixed model\u201d or \u201cLMM\u201d) is a standard way to analyze repeated-measures data.</p> <p>In FPVS-EEG, a repeated-measures structure happens any time each participant contributes multiple values\u2014for example, one Summed BCA value for each condition and each ROI. Those values are related because they come from the same person, so treating them as independent would be statistically inappropriate.</p> <p>A mixed model handles this by combining two ideas:</p> <ul> <li>Fixed effects describe the average pattern for the group.   In this toolbox, that means estimating how Summed BCA changes across   conditions, across ROIs, and whether condition effects differ by ROI.</li> <li>Random effects describe participant-to-participant differences.   The default toolbox model uses a random intercept, which means each   participant is allowed to have their own overall baseline response   level (some participants are consistently higher or lower across all   conditions/ROIs, independent of the experimental manipulation).</li> </ul> <p>Why this is useful in FPVS-EEG research:</p> <ul> <li>It matches the reality that FPVS datasets are usually   subject \u00d7 condition \u00d7 ROI.</li> <li>It gives interpretable answers to the same questions you would ask   with repeated-measures ANOVA (condition effects, ROI effects, and the   interaction), while explicitly accounting for subject-to-subject   variability in overall response magnitude.</li> <li>It can be more tolerant of minor imbalance (e.g., a small number of   missing condition\u00d7ROI cells after exclusions) than approaches that   require perfectly complete data tables.</li> </ul>"},{"location":"statistics/mixed-model/#more-details","title":"More Details","text":""},{"location":"statistics/mixed-model/#model-specification-implemented-in-the-toolbox","title":"Model specification implemented in the toolbox","text":"<p>Summed BCA values are analyzed using linear mixed-effects modeling to account for repeated measurements within participants. The dependent variable is ROI-level Summed BCA (ROI-averaged baseline-corrected amplitude summed across the set of statistically significant oddball harmonics defined for the analysis). Data are indexed by participant, condition, and ROI.</p> <p>Models are fit in Python using statsmodels (<code>MixedLM</code>) with a participant-level random intercept. For single-group analyses, fixed effects included Condition, ROI, and the Condition \u00d7 ROI interaction. For multi-group analyses, Group was included as an additional fixed effect along with all interactions among Group, Condition, and ROI. This specification estimates group-average effects of condition and ROI while allowing each participant to vary in overall baseline response level via the random intercept.</p>"},{"location":"statistics/mixed-model/#categorical-coding-and-interpretation","title":"Categorical coding and interpretation","text":"<p>Condition and ROI are sum-coded (sum-to-zero contrasts) when present, so fixed-effect coefficients are interpreted as deviations from the grand mean across factor levels rather than comparisons to an arbitrary reference level. Under this coding:</p> <ul> <li>The intercept represents the grand mean Summed BCA across included   factor levels.</li> <li>Condition and ROI terms reflect how each level deviates from   that grand mean.</li> <li>The Condition \u00d7 ROI interaction tests whether condition-related   changes differ across ROIs (i.e., whether the condition effect depends   on ROI).</li> </ul> <p>Group contrasts are not explicitly configured in the current workflow, so group terms follow the default contrast handling used by statsmodels.</p>"},{"location":"statistics/mixed-model/#practical-relationship-to-rm-anova","title":"Practical relationship to RM-ANOVA","text":"<p>RM-ANOVA provides a familiar summary test for within-subject designs, but it is most straightforward when every participant contributes a complete, balanced set of condition\u00d7ROI observations. The mixed model addresses the same repeated-measures structure while explicitly modeling participant-to-participant differences (via the random intercept) and can use all available observations when a small number of cells are missing rather than dropping entire participants due to listwise deletion.</p>"},{"location":"statistics/outliers-and-qc/","title":"Outliers, QC flags, and manual exclusions","text":""},{"location":"statistics/outliers-and-qc/#plain-language-overview","title":"Plain-language overview","text":"<p>FPVS datasets can contain participants with unusually large values, missing values, or other issues that might distort group statistics. This module helps you handle that cleanly by separating two concepts:</p> <ul> <li>Flags: warnings that say \u201cthis looks unusual, and you should take a look.\u201d</li> <li>Exclusions: a decision to actually remove a participant from the   analysis.</li> </ul> <p>The point is to avoid \u201csilent\u201d data removal. You get a transparent paper trail showing what was flagged, what was excluded, and why.</p> <p>Why this is useful in FPVS-EEG research:</p> <ul> <li>It supports transparent QC reporting (what you noticed vs. what you   removed).</li> <li>It reduces the chance of accidentally biasing results by   auto-dropping participants without review.</li> <li>It produces exported reports you can archive with the project and   use directly when writing your Methods/QC section.</li> </ul>"},{"location":"statistics/outliers-and-qc/#manuscript-ready-description","title":"Manuscript-ready description","text":""},{"location":"statistics/outliers-and-qc/#conceptual-approach","title":"Conceptual approach","text":"<p>Quality control in the FPVS Toolbox distinguishes between informational QC flags and analysis exclusions. QC flags identify participants with unusually large responses or implausible outcome values, but flagged participants are not automatically removed from analysis. Instead, flags are exported as a structured report to support review, documentation, and transparent reporting. Exclusions are applied only in two cases: (1) required exclusions triggered by non-finite outcome values, and (2) manual exclusions selected by the user after reviewing QC outputs.</p>"},{"location":"statistics/outliers-and-qc/#qc-flags-and-dv-limit-flags","title":"QC flags and DV limit flags","text":"<p>QC screening is computed across all conditions and ROIs in the active project, independent of any subset later selected for inferential analysis. Robust outlier screening is performed using harmonic-level BCA-derived summary metrics, including sum(|BCA|) and max(|BCA|) computed across oddball harmonics, in order to identify unusually large responses that may reflect artifact, preprocessing failures, or other non-physiological outliers. In addition, an optional hard absolute limit can be applied to the dependent variable (Summed BCA); observations exceeding this limit are recorded as DV hard-limit flags. QC and DV flags are informational and are intended to prompt review rather than enforce removal.</p>"},{"location":"statistics/outliers-and-qc/#required-and-manual-exclusions","title":"Required and manual exclusions","text":"<p>Participants with non-finite Summed BCA values (e.g., NaN or \u00b1Inf) are treated as required exclusions and are automatically removed from all inferential analyses because their outcomes cannot be modeled. All other exclusions are user-controlled: after reviewing QC reports, the user may manually designate participants to exclude, and these manual exclusions are applied prior to running statistical tests. As a result, the final analytic sample reflects only (a) required non-finite exclusions and (b) user-selected manual exclusions, while QC flags remain as a transparent record of potential data-quality concerns.</p>"},{"location":"statistics/outliers-and-qc/#outputs-for-documentation","title":"Outputs for documentation","text":"<p>QC and exclusion outputs are exported to the project results directory under \u201c3 - Statistical Analysis Results\u201d. The toolbox generates a Flagged Participants report (summarizing QC and DV flags) and an Excluded Participants report (recording required non-finite exclusions and user-selected manual exclusions), enabling clear documentation of data review decisions in manuscripts and reproducible project archiving.</p>"},{"location":"statistics/posthoc-tests/","title":"Post-hoc tests (interaction breakdown)","text":""},{"location":"statistics/posthoc-tests/#plain-language-overview","title":"Plain-language overview","text":"<p>Sometimes the main statistics tell you that an effect exists, but not where it comes from.</p> <p>If the repeated-measures ANOVA finds a Condition \u00d7 ROI interaction, that means the size (or even the direction) of condition differences depends on which ROI you\u2019re looking at.</p> <p>This post-hoc module answers the practical follow-up question:</p> <ul> <li>\u201cWithin a given ROI, which specific condition pairs are different?\u201d</li> </ul> <p>It does this in a way that matches the repeated-measures structure of FPVS data (the same participants contribute all conditions).</p> <p>Why this is useful in FPVS-EEG research:</p> <ul> <li>It turns an interaction result into an interpretable set of   ROI-specific comparisons you can report in Results.</li> <li>It keeps the comparisons within-subject, which is usually the   appropriate design for FPVS condition contrasts.</li> <li>It produces a standardized export so post-hoc reporting is consistent   across projects.</li> </ul>"},{"location":"statistics/posthoc-tests/#manuscript-ready-description","title":"Manuscript-ready description","text":"<p>Following detection of a significant Condition \u00d7 ROI interaction in the repeated-measures ANOVA, ROI-stratified post-hoc testing was performed to identify which condition pairs differed within each ROI. For each ROI, all pairwise comparisons between conditions were evaluated using paired-samples t-tests, computed on subject-wise differences so that each participant served as their own control. Multiple comparisons were controlled using the Benjamini\u2013Hochberg false discovery rate (FDR) procedure (<code>fdr_bh</code>), applied separately within each ROI such that the family of tests consisted of all condition-pair comparisons for that ROI.</p> <p>For each condition pair, results included the t statistic and associated p-value (both raw and FDR-adjusted), the mean paired difference (Condition A \u2212 Condition B) with a 95% confidence interval, and the paired-samples effect size Cohen\u2019s dz, computed as the mean of the paired differences divided by the standard deviation of the paired differences. As an informational diagnostic, a Shapiro\u2013Wilk normality test was applied to the paired differences; this value was reported but did not alter the inferential procedure. Positive mean differences indicate larger Summed BCA values in Condition A than Condition B within the ROI, and larger absolute dz values indicate stronger condition separation.</p>"},{"location":"statistics/rm-anova/","title":"RM-ANOVA details (Summed BCA)","text":""},{"location":"statistics/rm-anova/#plain-language-overview","title":"Plain-language overview","text":"<p>Repeated-measures ANOVA (RM-ANOVA) is a standard way to test whether an outcome changes across multiple conditions and/or multiple ROIs when the same participants contribute data in every cell.</p> <p>In FPVS terms, RM-ANOVA asks questions like:</p> <ul> <li>Do Summed BCA values differ across conditions (on average)?</li> <li>Do Summed BCA values differ across ROIs (on average)?</li> <li>Does the size of the condition effect depend on ROI   (Condition \u00d7 ROI interaction)?</li> </ul> <p>RM-ANOVA is useful when your dataset is complete and balanced: every participant must have a Summed BCA value for every required condition \u00d7 ROI combination. If that\u2019s true, RM-ANOVA provides a clean, familiar summary test of within-subject effects.</p> <p>Important practical notes:</p> <ul> <li>RM-ANOVA tests differences among factor levels (condition/ROI).   It does not directly test whether Summed BCA is different from zero.</li> <li>RM-ANOVA relies on assumptions about the covariance structure of   repeated measures (often discussed as \u201csphericity\u201d). When correction   options are available, the toolbox reports corrected p-values to   reduce false positives if those assumptions are violated.</li> </ul>"},{"location":"statistics/rm-anova/#manuscript-ready-description","title":"Manuscript-ready description","text":"<p>ROI-averaged Summed BCA values were analyzed using repeated-measures ANOVA to evaluate within-subject effects of Condition, ROI, and their interaction (Condition \u00d7 ROI). RM-ANOVA was implemented using Pingouin. Results were normalized into a consistent reporting table containing the F statistic, numerator and denominator degrees of freedom, and p-values for each effect. When available from the underlying library, Greenhouse\u2013Geisser and Huynh\u2013Feldt corrected p-values were additionally reported to address potential violations of repeated-measures assumptions. Effect sizes were reported as partial eta squared; when not provided directly by the library, partial eta squared was computed from the F statistic and its associated degrees of freedom. Because RM-ANOVA requires a balanced within-subject table, analyses were only performed when each participant contributed observations for all required condition \u00d7 ROI combinations; otherwise, the analysis halted and reported the missing cells.</p>"},{"location":"statistics/rm-anova/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following detail was not found in the current workflow:</p> <ul> <li>A user-facing option to manually select which sphericity correction   method to report (corrected columns are reported only when provided by   the library).</li> </ul>"},{"location":"statistics/rossion-harmonic-selection/","title":"Rossion harmonic selection (Summed BCA)","text":""},{"location":"statistics/rossion-harmonic-selection/#plain-language-overview","title":"Plain-language overview","text":"<p>In FPVS, the oddball response is not limited to a single frequency. If the brain is truly responding to the oddball stream, you often see a response at the oddball frequency (e.g., 1.2 Hz) and at several higher harmonics (2.4, 3.6, 4.8, ...).</p> <p>This module decides which oddball harmonics count toward the outcome used for statistics: Summed BCA.</p> <p>The key idea (the \u201cRossion method\u201d) is simple:</p> <ul> <li>Look at the group-level Z-scores at each oddball harmonic.</li> <li>For each ROI, include the harmonics that show a reliable group   response, and stop when the response clearly dies off.</li> </ul> <p>Why this is useful in FPVS-EEG research:</p> <ul> <li>It produces an outcome measure that reflects the total oddball   response across the harmonics that actually carry signal.</li> <li>It is ROI-specific, which matters because different scalp regions   can show different harmonic profiles.</li> <li>It creates a single, interpretable number per   participant \u00d7 condition \u00d7 ROI that can be used in RM-ANOVA, mixed   models, and post-hoc tests.</li> </ul>"},{"location":"statistics/rossion-harmonic-selection/#manuscript-ready-description","title":"Manuscript-ready description","text":"<p>Summed BCA was defined using an ROI-specific harmonic selection procedure based on the approach commonly attributed to work done by the Rossion Group. Harmonic selection was performed at the group level using ROI-averaged Z-scores derived from the spectral \u201cZ Score\u201d sheets in the per-subject, per-condition output files. Candidate frequencies were restricted to oddball harmonics present in the spectral exports, identified as multiples of the oddball rate (base frequency divided by <code>every_n</code>, default <code>every_n = 5</code>) within a tolerance, and excluding base-rate harmonics (exact multiples of the base frequency). An optional setting allowed exclusion of the first oddball harmonic (harmonic 1).</p> <p>For each candidate harmonic, Z-scores were first averaged across the channels belonging to each ROI, yielding ROI-mean Z values for each subject and condition. These ROI-mean Z values were then pooled across subjects and across the set of selected conditions and averaged to yield a group mean Z for each ROI \u00d7 harmonic. Within each ROI, harmonics were scanned in ascending frequency order and evaluated against a user-defined Z threshold (default 1.64). Non-significant harmonics were ignored until the first significant harmonic was observed (\u201carming\u201d step). After arming, the selection terminated when two consecutive harmonics failed to exceed threshold. The selected harmonic set for each ROI consisted of all significant harmonics encountered prior to the stop criterion.</p> <p>Summed BCA values were then computed for each subject \u00d7 condition \u00d7 ROI by extracting baseline-corrected amplitude (BCA; \u00b5V) at the selected harmonics from the \u201cBCA (uV)\u201d sheets, summing BCA across the selected harmonics within each channel, and then averaging across channels within the ROI. This yielded a single ROI-level Summed BCA outcome per condition and participant, which served as the dependent variable for inferential analyses.</p> <p>If no harmonics were selected for a given ROI, an empty-list policy was applied. Depending on user settings, the toolbox either (a) fell back to a Fixed-K harmonic set (default K = 5) drawn from the same oddball harmonic domain, (b) set Summed BCA to zero for that ROI, or (c) halted with an error to prompt adjustment of selection settings. The toolbox exports a dedicated report (\u201cSummed BCA DV Definition.xlsx\u201d) documenting the harmonic domain, group mean Z values, ROI-specific selected harmonic lists, and any fallback behavior.</p>"},{"location":"statistics/rossion-harmonic-selection/#not-found-in-code-documentation-transparency","title":"Not found in code (documentation transparency)","text":"<p>The following detail was not found in the current workflow:</p> <ul> <li>A more specific UI label/description for the Z-threshold setting beyond   the functional meaning \u201cminimum group-mean Z value for a harmonic to   count as significant.\u201d</li> </ul>"},{"location":"tools/individual-level-detectability/","title":"Individual-level Detectability","text":""},{"location":"tools/individual-level-detectability/#technical-documentation","title":"Technical documentation","text":""},{"location":"tools/individual-level-detectability/#purpose-and-scope","title":"Purpose and scope","text":"<p>The individual-level detectability tool generates per-condition, participant-level detectability figures from  existing FPVS Toolbox Excel exports. It does not recompute FFT/BCA/SNR/Z metrics; it only reads the exported  sheets and produces figures. Each participant panel contains (i) a scalp topomap of Stouffer-combined Z scores across  oddball harmonics and (ii) a centered SNR mini-spectrum panel around each harmonic, averaged across significant  electrodes and then across harmonics. </p>"},{"location":"tools/individual-level-detectability/#required-inputs-excel-format","title":"Required inputs (Excel format)","text":"<p>The script expects that you have already run the processing pipeline on your dataset, which generates .xlsx files  for each participant. This tool reads data from these excel sheets to generate figures. </p> <ul> <li>Sheet <code>Z Score</code></li> <li>Electrode column: <code>Electrode</code>.</li> <li>Harmonic columns named like <code>1.2000_Hz</code>. Only the frequencies in <code>ODDBALL_HARMONICS_HZ</code> are required. Missing </li> <li> <p>harmonic columns raise a hard error.</p> </li> <li> <p>Sheet <code>FullSNR</code></p> </li> <li>Electrode column: <code>Electrode</code>.</li> <li>Frequency columns named <code>*_Hz</code> covering bins within \u00b1<code>HALF_WINDOW_HZ</code> around each oddball harmonic. The script </li> <li>filters columns by frequency to keep only the bins needed for the mini-spectrum window.</li> </ul> <p>The tool uses the oddball harmonic list, excluding the base frequency and its harmonics, for figure generation.</p>"},{"location":"tools/individual-level-detectability/#z-score-combination-across-harmonics-stouffer","title":"Z-score combination across harmonics (Stouffer)","text":"<p>For each electrode, the script combines Z-scores across the oddball harmonics via Stouffer\u2019s method:</p> <ul> <li>Let k be the number of oddball harmonics.</li> <li>For each electrode, collect Z values <code>z_i</code> at each harmonic.</li> <li>Compute:</li> </ul> <pre><code>Z_comb = (sum_{i=1..k} z_i) / sqrt(k)\n</code></pre> <p>Significance thresholding is one-tailed and positive direction only:</p> <ul> <li>Significant if <code>Z_comb &gt;= Z_THRESHOLD</code> (default <code>1.64</code>).</li> </ul>"},{"location":"tools/individual-level-detectability/#fdr-correction-benjaminihochberg","title":"FDR correction (Benjamini\u2013Hochberg)","text":"<p>If <code>USE_BH_FDR</code> is enabled (default <code>True</code>), the script applies BH-FDR correction to the combined Z values:</p> <ul> <li>Convert combined Z to one-tailed p-values: <code>p = 1 \u2212 \u03a6(Z_comb)</code>.</li> <li>Apply BH-FDR at <code>alpha = FDR_ALPHA</code> (default <code>0.05</code>).</li> <li>Scope: across electrodes within a participant file (per participant, per condition).</li> <li>Final significance mask is the intersection of the Z threshold and BH reject decisions: </li> <li><code>(Z_comb &gt;= Z_THRESHOLD) AND (BH reject)</code>.\u3011</li> </ul> <p>Dependency behavior:</p> <ul> <li>Uses <code>statsmodels.stats.multitest.multipletests(method=\"fdr_bh\")</code> </li> </ul> <p>Montage behavior:</p> <ul> <li>Uses <code>MONTAGE_NAME = \"biosemi64\"</code>.</li> <li>Electrode names are normalized before matching.</li> <li>In <code>DEBUG</code> mode, any mapping failure raises an error to surface label issues early.</li> </ul>"},{"location":"tools/individual-level-detectability/#snr-mini-spectrum-computation","title":"SNR mini-spectrum computation","text":"<p>For each participant:</p> <ol> <li>Determine significant electrodes from the combined Z significance mask.</li> <li>Pull the <code>FullSNR</code> values for those electrodes.</li> <li>For each harmonic <code>f</code>:</li> <li>Extract bins in <code>[f \u2212 HALF_WINDOW_HZ, f + HALF_WINDOW_HZ]</code>.</li> <li>Convert to relative frequency <code>x = (bin \u2212 f)</code>.</li> <li>Average across significant electrodes at each bin.</li> <li>Align relative-frequency bins across harmonics (rounded to 4 decimals) and average across harmonics to produce a single centered SNR curve.</li> </ol> <p>Display rules:</p> <ul> <li>Fixed x-limits: \u00b1<code>HALF_WINDOW_HZ</code>.</li> <li>Fixed y-limits: <code>[SNR_YMIN_FIXED, SNR_YMAX_FIXED]</code> (defaults <code>0</code> to <code>2</code>).</li> <li>Reference lines: vertical at <code>0 Hz</code>, horizontal at <code>SNR = 1</code>.</li> <li>If <code>n_sig &lt;= 0</code> (or the curve is missing), the SNR panel is hidden entirely.</li> </ul>"},{"location":"tools/individual-level-detectability/#figure-layout-export","title":"Figure layout + export","text":"<p>Layout defaults to letter-size portrait output for manuscript use:</p> <ul> <li><code>USE_LETTER_PORTRAIT = True</code> produces an 8.5\u00d711 in figure with reserved title and colorbar bands.</li> <li>Grid bounds are computed from <code>PAGE_MARGIN_IN</code>, <code>TITLE_BAND_IN</code>, and <code>COLORBAR_BAND_IN</code>.</li> <li>A centered horizontal colorbar is placed in the reserved band.</li> </ul> <p>Export behavior:</p> <ul> <li><code>FIG_DPI = 600</code>, format PNG.</li> <li>In letter mode, the figure is saved without <code>bbox_inches=\"tight\"</code> to preserve physical size.</li> <li>Figure title uses Times New Roman; a blank title omits the suptitle entirely.</li> <li>Output filename stems are sanitized for Windows compatibility via the PySide6 naming dialog.</li> </ul>"},{"location":"tools/individual-level-detectability/#reproducibility-recommended-reporting","title":"Reproducibility + recommended reporting","text":"<p>When reporting results generated with this tool, include:</p> <ul> <li>Harmonics list: <code>ODDBALL_HARMONICS_HZ</code> and exclusion of <code>SKIP_BASE_FREQ_HZ</code> (6 Hz).</li> <li>Stouffer combination formula for <code>Z_comb</code> and one-tailed threshold (<code>Z_THRESHOLD = 1.64</code>).</li> <li>BH-FDR settings (<code>USE_BH_FDR = True</code>, <code>FDR_ALPHA = 0.05</code>) and per-participant electrode scope.</li> <li>SNR window (<code>HALF_WINDOW_HZ = 0.2 Hz</code>), fixed SNR y-axis (<code>0\u20132</code>), and reference lines.</li> <li>Montage (<code>biosemi64</code>) and finite-vector topomap rendering strategy (non-sig set to threshold).</li> </ul>"},{"location":"tools/individual-level-detectability/#relation-to-prior-figure-styles","title":"Relation to prior figure styles","text":"<p>A similar figure style appears in David et al. (2025), and the per-participant grid layout with topomap plus centered  SNR mini-spectrum is aligned with that style for visual comparability in individual-level reporting.</p> <p>David, J., Quenon, L., Hanseeuw, B., Ivanoiu, A., Volfart, A., Koessler, L., &amp; Rossion, B. (2025).  An objective and sensitive electrophysiological marker of word semantic categorization impairment in Alzheimer's  disease. Clinical Neurophysiology, 170, 98\u2013109. https://doi.org/10.1016/j.clinph.2024.12.018.\u3010F:docs/relevant-publications.md\u2020L21-L28\u3011</p>"},{"location":"tools/individual-level-detectability/#manuscript-thesis-ready-text-copypaste","title":"Manuscript / thesis-ready text (copy/paste)","text":"<p>The individual-level detectability tool generates participant-level detectability figures. For each participant and condition,  Z scores at the oddball harmonics are combined with Stouffer\u2019s method (Z_comb = sum(z_i)/\u221ak), thresholded one-tailed in the positive direction  (Z_comb \u2265 1.64), and further filtered via Benjamini\u2013Hochberg FDR across electrodes within each participant  file (\u03b1 = 0.05). The resulting topomap is rendered with a finite vector: non-significant electrodes are rendered as  white. A centered SNR mini-spectrum is computed by averaging FullSNR bins within \u00b10.2 Hz of each oddball harmonic  across significant electrodes, aligning relative-frequency bins across harmonics, and averaging across harmonics, with  fixed axes and reference lines for interpretability. </p> <p>Text and figure-generation approach may be reused with attribution; cite the FPVS Toolbox using the project\u2019s preferred  citation (Murphy, Z. FPVS Toolbox: Automated preprocessing and statistical analysis for fast periodic visual  stimulation EEG experiments; manuscript in preparation).</p>"}]}